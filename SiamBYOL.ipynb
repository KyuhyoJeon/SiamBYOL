{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SiamBYOL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KyuhyoJeon/SiamBYOL/blob/main/SiamBYOL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U0mliCb7ZTj"
      },
      "source": [
        "# ### Google drive mount ###\r\n",
        "# from google.colab import drive \r\n",
        "# drive.mount('/content/gdrive/')\r\n",
        "# ### ------------------------------------------ ###"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbTSofU9NHbz"
      },
      "source": [
        "### Arguments define ###\r\n",
        "import easydict\r\n",
        "import os\r\n",
        "from datetime import datetime\r\n",
        "\r\n",
        "args = easydict.EasyDict({\r\n",
        "    'image_size':32, # original = 224\r\n",
        "    'learning_rate':0.2, # original lr = 0.2, others = 0.3 or 3e-4\r\n",
        "    'momentum':0, \r\n",
        "    'weight_decay':1.5e-6, \r\n",
        "    'batch_size':4096, \r\n",
        "    'num_epochs':1000, \r\n",
        "    'warmup_epochs':10, \r\n",
        "    'resnet_version':'resnet50', # original = resnet50\r\n",
        "    'optim':'sgd', \r\n",
        "    'checkpoint_epochs':10, \r\n",
        "    # ********************MUST CHECK********************** #\r\n",
        "    'dataset_dir':'./datasets', # dataset directory\r\n",
        "    'ckpt_dir':'/content/gdrive/MyDrive/Colab Notebooks/siambyol/ckpt',   # Network checkpoint directory\r\n",
        "    'num_workers':8, \r\n",
        "    'nodes':1, \r\n",
        "    'gpus':1, \r\n",
        "    'nr':0, \r\n",
        "    'device':'cuda', \r\n",
        "    'eval':True, \r\n",
        "    'eval_epochs':30, \r\n",
        "    # ********************MUST CHECK********************** #\r\n",
        "    'dryrun':True, # check line 47~53\r\n",
        "    'debug':True, # check line 56~62\r\n",
        "    'current_epochs':0, \r\n",
        "    'data_load_check':False\r\n",
        "})\r\n",
        "\r\n",
        "# ********************MUST CHECK********************** #\r\n",
        "# dryrun setting\r\n",
        "if args.dryrun:\r\n",
        "  args.image_size=32\r\n",
        "  args.num_epochs = 100\r\n",
        "  args.batch_size = 256\r\n",
        "  args.num_workers = 4\r\n",
        "  args.resnet_version = 'resnet18'\r\n",
        "\r\n",
        "# ********************MUST CHECK********************** #\r\n",
        "# debug setting\r\n",
        "if args.debug:\r\n",
        "  args.image_size=32\r\n",
        "  args.num_epochs = 1\r\n",
        "  args.batch_size = 2\r\n",
        "  args.num_workers = 0\r\n",
        "  args.debug_subset_size = 8\r\n",
        "  args.resnet_version = 'resnet18'\r\n",
        "  args.eval = False\r\n",
        "  args.data_load_check = True\r\n",
        "  \r\n",
        "\r\n",
        "# make check point directory ex: \"ckpt_dir/resnet18/lars/021805\"\r\n",
        "tmp_dir = os.path.join(args.ckpt_dir, f\"{args.resnet_version}\", f\"{args.optim}\", f\"{datetime.now().strftime('%m%d%H')}\")\r\n",
        "if args.debug:\r\n",
        "  tmp_dir = os.path.join(args.ckpt_dir, f\"{args.resnet_version}\", f\"{args.optim}\", f\"debug\")\r\n",
        "if not os.path.exists(tmp_dir):\r\n",
        "  os.makedirs(tmp_dir)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwAPPgDwNo2j"
      },
      "source": [
        "### Image augmentation define\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "from torchvision import datasets, transforms\r\n",
        "\r\n",
        "class simclr_transform:\r\n",
        "  # augmentations: \r\n",
        "  # random patch, 224 resize, random hrizontal flip, color distortion, \r\n",
        "  # random swquence brightness, contrast, saturation, hue adjustment, \r\n",
        "  # and optional gray scale conversion, Gaussian blur, solarization\r\n",
        "  imagenet_mean_std = [[0.485, 0.456, 0.406],[0.229, 0.224, 0.225]]\r\n",
        "  def __init__(self, size, mean_std=imagenet_mean_std, s=1.0):\r\n",
        "    self.transform = transforms.Compose(\r\n",
        "        [\r\n",
        "        transforms.RandomResizedCrop(size=size), ###\r\n",
        "        transforms.RandomHorizontalFlip(), \r\n",
        "        transforms.RandomApply(\r\n",
        "            [transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)], p=0.8),\r\n",
        "        transforms.RandomGrayscale(p=0.2),\r\n",
        "        transforms.RandomApply(\r\n",
        "            [transforms.GaussianBlur(kernel_size=size//20*2+1, sigma=(0.1, 2.0))], p=0.5), \r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize(*mean_std)\r\n",
        "        ]\r\n",
        "    )\r\n",
        "  def __call__(self, x):\r\n",
        "    x1 = self.transform(x)\r\n",
        "    x2 = self.transform(x)\r\n",
        "    return x1, x2\r\n",
        "\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "class Transform_single():\r\n",
        "  imagenet_mean_std = [[0.485, 0.456, 0.406],[0.229, 0.224, 0.225]]\r\n",
        "  def __init__(self, size, train, normalize=imagenet_mean_std):\r\n",
        "    if train == True:\r\n",
        "      self.transform = transforms.Compose(\r\n",
        "          [\r\n",
        "           transforms.RandomResizedCrop(size, scale=(0.08, 1.0), \r\n",
        "                                        ratio=(3.0/4.0,4.0/3.0), \r\n",
        "                                        interpolation=Image.BICUBIC\r\n",
        "                                        ),\r\n",
        "           transforms.RandomHorizontalFlip(),\r\n",
        "           transforms.ToTensor(),\r\n",
        "           transforms.Normalize(*normalize)\r\n",
        "          ]\r\n",
        "      )\r\n",
        "    else:\r\n",
        "      self.transform = transforms.Compose(\r\n",
        "          [\r\n",
        "           transforms.Resize(int(size*(8/7)), \r\n",
        "                             interpolation=Image.BICUBIC\r\n",
        "                             ), # 224 -> 256 \r\n",
        "           transforms.CenterCrop(size),\r\n",
        "           transforms.ToTensor(),\r\n",
        "           transforms.Normalize(*normalize)\r\n",
        "          ]\r\n",
        "      )\r\n",
        "\r\n",
        "  def __call__(self, x):\r\n",
        "    return self.transform(x)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5jUb9pev062",
        "outputId": "71b73e2c-c6e8-46f0-a136-c691909c759a"
      },
      "source": [
        "### dataset load ###\r\n",
        "cifar_train = datasets.CIFAR10(\r\n",
        "    root=args.dataset_dir, \r\n",
        "    train=True, \r\n",
        "    transform=simclr_transform(args.image_size), \r\n",
        "    download=True\r\n",
        ")\r\n",
        "\r\n",
        "if args.debug:\r\n",
        "  cifar_train = torch.utils.data.Subset(cifar_train, range(0, args.debug_subset_size))\r\n",
        "  cifar_train.classes = cifar_train.dataset.classes\r\n",
        "  cifar_train.targets = cifar_train.dataset.targets\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(\r\n",
        "    cifar_train, \r\n",
        "    batch_size=args.batch_size, \r\n",
        "    shuffle=True, \r\n",
        "    num_workers=args.num_workers, \r\n",
        "    drop_last=True, \r\n",
        "    pin_memory=True\r\n",
        ")\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sSKUET0IL1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "9c6d8f64-e095-4504-e254-adae936b7153"
      },
      "source": [
        "### dataset load check ###\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def imshow(img):\r\n",
        "  img = img / 2 + 0.5     # unnormalize\r\n",
        "  npimg = img.numpy()\r\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "if args.data_load_check:\r\n",
        "  dataiter = iter(train_loader)\r\n",
        "  (images1, images2), labels = dataiter.next()\r\n",
        "\r\n",
        "  imshow(torchvision.utils.make_grid(images1))\r\n",
        "  imshow(torchvision.utils.make_grid(images2))\r\n",
        "  print(' '.join('%5s' % train_loader.dataset.classes[labels[j]] for j in range(len(labels))))\r\n",
        "  ### ------------------------------------------ ###"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADNCAYAAAChOisgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2de5TdZXnvv08mM5NMCLkICeFSCChysOcQcAQ9WkSUFpUWrbVHlnXhOnTFnlXX0ta2Ru2p5qzTlnpaaVcv2lgRai1ouRTK0SK3HksvQIIhhESuoiQmBAy5zYSZzMxz/ti/HGc/73ey39n7N5f35PtZa1bmfeb9/X7P/u097+y83/19HnN3CCGEKI85M52AEEKI9tACLoQQhaIFXAghCkULuBBCFIoWcCGEKBQt4EIIUSgdLeBmdqmZPW5mT5nZmrqSEkII0Rpr93PgZtYF4AkAlwDYBuAhAFe4+5b60hNCCDERczs49nwAT7n7MwBgZjcCuBzAhAt4X1+fL168uINLCiHE0ceOHTtedPfjY7yTBfwkAM+NG28DcMGRDli8eDFWr17dwSWFEOLoY+3atd9n8SkXMc1stZmtN7P1g4ODU305IYQ4auhkAd8O4JRx45OrWBPuvs7d+929v6+vr4PLCSGEGE8nC/hDAF5lZivNrAfA+wDcXk9aQgghWtH2Hri7j5jZhwHcCaALwLXu/lhtmQkhhDginYiYcPdvAPhGTbkIIYSYBHJiCiFEoWgBF0KIQuloC2WquHLtXzSNV+KXyazzSexsEjshjNnHKfeT2BMk9jSJrQrjY8mc+0iM5bGXxOaH8QIy5/7M81/YNDrY9CGiBs8lEeBMLCLRV5LY7qbRAfLyOqbnU63SasBu/w9i4E4y6R+TyBDuTmK//+n3kGObueXux5NYT29vy+MAYGxstGk8d2531nHDw0NJbGhoOIl1z22+t7l5jYwcypqXQ+5japfe3p4kdujQSBLLeUwj5Li53a2XP3bcEHmOhslzNG9+/N0Fhoeaj/3A5ee1zOFI6B24EEIUihZwIYQoFC3gQghRKLNyD3wlLguRpWQW+9tzkMR2hjHbZ2Y7v4x3kljcC/5XMuc1JDZGYule/G7c1DT+P+SoV5DYhXg3iZ7aNNqOe5MZ12BTEmO77v+BvHR+Cu9vGp95xnXpgQvJydKtQh5LYHvzqQbRixNzTpYwNpY+R3v37Elic7pavw+aM6cricV97MlwaGTkiGMAmD9/XhIbG00fE3ucObD94TlzWt8Ldj22H832wHNg95pt19P8w3PJ9rGZ3vDy3HTtWXhs+mIfGkr3zztB78CFEKJQtIALIUShaAEXQohC0QIuhBCFMitFTOCMMGYGHWYkYUQJLjWvcJmOCTunklhkWea5UgHlH4gh5+owTiVGYC1+IoldiFtoduNhd/C3cUUS+3XcmMQGSP4/hRebA6nex71Qj/D8WsO6O7H7z57z1vQQEY2JUEwYjGaPLiKsdS1IX3fsmkwkjddkwiAT6Rij4dguIkTGObnnYrDzs3s4MDCQdc302DzzDaM7qJ05ouxE8w4eTIVN9jg7Qe/AhRCiULSACyFEoWgBF0KIQuloD9zMnkXDfTIKYMTd++tISgghRGvqEDHf4u4vtp42GaJzMdeJyaqjRSGBVR7MPT9T5aJgchyZ80AS+Sfck8R+Dy8lsX8nZ4sso8IdIRrzXk6nnIQbktgHyWPaiq8ksR+Glqhn/og1aDozDXm7Ve2Y+MzuxetIbEfLs/MKdnm5RlGxXbcjwAWyGGPV8Jg7k7k/mWMz0olI2i7s/EwkjZUfGbni4Zye9pykLMbuf91oC0UIIQql0wXcAXzLzDaY2eo6EhJCCJFHp1sob3L37Wa2DMBdZvZdd//2+AnVwr4aABYtYsWHhBBCtENH78DdfXv17y4At4K0yXH3de7e7+79fX19nVxOCCHEONp+B25mCwDMcff91fc/DeB/1JPWuzLmsDZKrA9XFAZZndJnSWw5ie0jsbPCeDOZc0cS+Tw2JrHdSQQ4KYyZbHcFTidRAhEtc3g71iSxM4jw+xKa/vOF2/DhZM5+UgL2l6jI+F4SiwIouxvMLRufIwC4mcSaYU5AVko0p+zpyKH09coFuTSW4wZkc3JahjWObXaJ5rYyY9dsN396HHGg9lDHY/MLmzk9c1e6+Px2k3vIHJYMmkfNdLKFshzArWZ2+Dx/6+5pQ0IhhBBTQtsLuLs/A+CcGnMRQggxCfQxQiGEKBQt4EIIUSizs5xs1DBZH8UHiSPu8Sj5MVIRCjiBxJikmHzIhrgbb0+m3Iq7kxjzfl4OI1dsLvr6s7gkmdNFYvWS3tcz8TtkXix2+7VkxneIKxXYRmLs/keYIJ3zGsiDCWtMmGIiXY6wyVyRc1nzRsLISLMomisCsvPH/HOdhrnEY3NLtDIn5qLFqQjeG4THUeK6jPdrIuaHHpgsVybo1l0mNhe9AxdCiELRAi6EEIWiBVwIIQpldu6BLwljttV5LIn1kBZbwyHGtibZ+YfIXurPkXkbwvjp9G/iu3EiibF9d/apzAvC+ENkzgzw/rRFGD57bvP4pHOTKefiv5OTPUNiW0gs3ltmtmLVCNkT3Jp589Pjcvdv415zbuU+Zhxhe64RZgoaJRUKe3qYBhSOy63cR9rEMXIqM+beV3bsgtCajhmwxsbSXFkVw7hXzu4Xe46GSas9Vo0wp3LiZNA7cCGEKBQt4EIIUShawIUQolC0gAshRKHMThEz6lesCxrTuGjLsyBiproOMMxEtP+dhjaQnhVPR5GDGTGuIDEmtv2XNLQoVNfbSw6rk1eTWOxwBwB/k3GuPySx3/gYCa4jMVY7nhipEuoTiVirsVj5DuDCWhRAmSDKzCU5giWQiqS5FfIYMX8m0rFYrogZH+cQEfxyDUz796WLQby37Fy59zXmxgTdXKMTFzbzDEW56B24EEIUihZwIYQoFC3gQghRKC0XcDO71sx2mdnmcbGlZnaXmT1Z/RutN0IIIaaYHBHzOgB/BuCvx8XWALjH3a82szXV+OO1ZbU9jFNj1QQQJ2ZSLfBRchwT0Z5KQ09Ty2aLMQDSkgw4jsQI14YxKzy4lsTeTGKxqiPrPsa60rHYD0nse2H8fTKHPUf0QbVb3S1PWMuBiXTUvUfapfWEaoSxyh3AhcFcF2QUBnuJY5BVIxwkLsXogswVLNt1pTJBsYvk2t2d3jPmsnw5CLhLlrBanykDAweSWLuuUdq+jujK3ZlibS4tn4Gqy3ys7Xk5gOur769HXhNLIYQQNdLuHvhyd99Rfb8TvCiFEEKIKaRjEdPdHYBP9HMzW21m681s/eDgYKeXE0IIUdHuAv68ma0AgOrfXRNNdPd17t7v7v19fX1tXk4IIUSkXSfm7QCuBHB19e9ttWUEAKeH8fNkDnNnMhPeyzGYOizvRtoGjZkPV+AYEo1K4C+SOZmCZdpRDfj5jOOY47FdVpLYmZnHxrcDrPzuDhK7KS07Wy/tuTOZU5KJUKNzmAuv2fLL3IFM2GTCIytFG4XGsV5STjZTEI3twNhxc+ak95A5KnPIbW+W05YOAAYONAubzPXKxGcuUre+Z0xwZc8REzYXLWIifvvkfIzwBgD/BuDVZrbNzK5CY+G+xMyeBPC2aiyEEGIaafkO3N1ZIQ8AeGvNuQghhJgEcmIKIUShaAEXQohCmZ3lZKPekGteoh9mvLdp9BS+kcxgUskJOIucPlXgDO8LEVLy9HfJBR4iMeZ4nA0wYZORtv5MeVvmuf4riX0558D6ynXmljhlv0RR1IpuQQAYHm6/rGoOzDHIhNMIc0qycrW5fT6ZMJvDEOnpya4ZY+x67HEzYTM+zrFR4lwl52dO2KVLU0fowoXRDt0ZegcuhBCFogVcCCEKRQu4EEIUyuzcA/+XOk/WvG/9LCmRdz75RKThdeRcC0jsPc3DfWQK2/Z6L4mlHbyOXmIVRgC4JYz3sjKVzFzSXmVD1hKL7X+yveZYjZDt3bLj2L4sIxpOesgeLKsqyFgS9mrZfi4zuDAjD6sWGPeVmZGH3Wu2787yWLCA/V6GvA6keQ0RDSLJlTxvC49Nf6GXLWctElPq1DgAvQMXQohi0QIuhBCFogVcCCEKRQu4EEIUyuwUMdsmNg4CgM1Noy/iB8mMf0baZm0tXkvO9R/T0IYwzv2cfuonAt6SeezRyt5nQuCbZNLZJMZKV7bm0Ahp/TXWWrAE0kp38+an4hWratcuuZUHe3pTgXLZsmYBjhlQmPjGRMadO1Oz20u7m38vebXANH9mfmImoygqsuNefPHFJMboCs/bCPLMSuz+0PZ7mZUYc9E7cCGEKBQt4EIIUShawIUQolByGjpca2a7zGzzuNhnzGy7mW2svt4xtWkKIYSI5IiY1wH4MwB/HeLXuHudzbxqIBVfgGbR5lTSt+yXcU7euZaQ1l/nZaT1QxJLuzkBl2Wc62jm+C3N4xdY+caoKgO8ZWt/y8sxhx8Tpnilu/qckozRjNZfzFHJHtPChcc2jZnQyVyj3SNp/qzl3IIFza0ImZMxtnUDgFFSuW+ECMvxcQ6R54M5RNk1k/Zyma3YmKDbbhXGydDyCu7+bfCPdwghhJhBOvkT8WEz21RtsSypLSMhhBBZtLuAfx7AGQBWoVEt6o8mmmhmq81svZmtHxwcbPNyQgghIm0t4O7+vLuPuvsYgC+CtqH5f3PXuXu/u/f39fW1m6cQQohAWyqKma1w98OWq3cj2h07JrqmjuvgXO9vGn2W/s1iPcOuSEPtKgH3kdhnSexX2jz/bGFvGC+q+fwvxMB3yST2UmQqcmsRk4mTrIRqTolQJlgyYZMJX0xsY+3YIkwsZMJmvCa9XmbpWJb/osXNLwQq+jIRkwi1zMkY7z9zxrJWZsy9GkvMMlF2/vy07jPLa85YKnYyMbgTWi7gZnYDgIsAHGdm2wB8GsBFZrYKjS6UzwL4UK1ZCSGEaEnLBdzdyVtRfGkKchFCCDEJ5MQUQohC0QIuhBCFMkvLycayoUw9ZMIjE5OiYHIqmXNmGnKWV43MVsHyRyT2isxj6xYtE6ILj70u6i3XGWECHBPuuoJYxQTLuZlOTCbwRViZVeoOJCJaLL+6d8+erLwYc+emj6k3ODtZDizG7k4vESij63VsND1XdIMCwP79aZnh4aFhctVmmBOTlcNl81ROVgghBAAt4EIIUSxawIUQolBm6R54NF6khgEg3d9L97uBdE/0nemUX1uelVXbsPTbhVUjYN2ibiWxb4fxPjKHdR87icS+QmJTbrSNm+w7yZx0r7ndlzmvPJiaOHLg++SsJCXJoyvdX43mFbYHvndPdFYBI2Re3PcdGDiQzGF7yLSyITEPsX3xHNgeMjNExcfOTE4sL9ZmrV2jTe5x7DF1gt6BCyFEoWgBF0KIQtECLoQQhaIFXAghCmWWipixP0QqoPAKhezvUVAQLyCC5efysmqb+0mMpf/zGeda8AgJspZwrFLfWc1D1objJaaIknO99k1p7JPk0Fp5Ooy3kTmsx90JbV2NmTO4YaP1+yAmHnZCNAH1jqUGl927X0pirJpiNNqwOUPE4MKMSAuRioU5wh0TjJnwm9NKjj0fzEjFRNglS5tbKbK8clvh0TZ0HbTRo9eo9WxCCCGmDS3gQghRKFrAhRCiUFou4GZ2ipndZ2ZbzOwxM/tIFV9qZneZ2ZPVv2psLIQQ00jOjvoIgI+5+8NmthDABjO7C8AHAdzj7leb2RoAawB8vJ60ouDDKggyWHW64M784OSz6ZgHSewxEnsliT0XA8syL3pWGjoxjFmnMSp+Pp+Gvkam1Sli0mqQ8XXAxG0mcrEb2xrWcotV+MtpqcboHkl//di5cqoW5jr8WDW8KMyyObnuxhyYMJh9bEZlxlxo67XwmHKvx+4Zi027iOnuO9z94er7/QC2omGuvhzA9dW06wG8q9bMhBBCHJFJ7YGb2WkAzgXwAIDl4xob7wQwxQVFhBBCjCd7ATezYwDcDOCj7t5UBsndHRP8p9fMVpvZejNbPzjIKjEJIYRoh6wF3My60Vi8v+rut1Th581sRfXzFQB2sWPdfZ2797t7f1/flJerE0KIo4aWO+pmZmh0od/q7uM9i7cDuBLA1dW/t9WXVvxbkFMmFgB2kNhrmof3kSlMI307y6tN+kmM3XmmCZ0dAyvazyMRLdk9PIXEiJNxE3GEWnCEvo2c6gmaWQrTJ3FHGKdlT4GNmbFPZybSDHMkslgOTNBi7kAm+kXhMbecKXOSHjz4ctN45BAT5FIn6QknpK9FJvpFMY/lyvJi5NwLdi4mwg4OpHWeY3u5XFF5LmnnyK6ZiuCdfXgvRxJ9I4APAHjUzA7/JnwSjYX762Z2FYDvA/jFjjIRQggxKVou4O5+PwCb4MdvrTcdIYQQuciJKYQQhaIFXAghCmWWlpONLsLUMQWkYg/wehILZSTvJFO+TmIXkNi/k1gOf5M5j2lhU1rqljkImaLLxM4M9+HduXk8SmJ/QWJfyD1hLTCRi9GuKDdCnJjM/Znj3uvpTculMsGPOUlj7CVShraXuBZzHZXtltJlAiITU/fva27kOkryYo+J3YvYX5P1GmUO2twStgOZr6lc9A5cCCEKRQu4EEIUihZwIYQoFC3gQghRKLNUxFwZxvvJnKUklooGCXszU3iAxH6PxE4P43eSOblVN5lWuyaM/5zMYa0hKXvCeHHmcbnlUqPYydRhJojeQGLfyrzm9MKELyYgdrXZJ5PFWB/I+fPntTz/MHGIMhFt4EBzLFeQYyVsD5ESqi++2NxnddtzSY1kKlguW56WTs7J/1hS5nb37rTUNLvXsQ8nuxcHD6aPMbeksHpiCiGEAKAFXAghikULuBBCFMos3QOP1NdGKZvYfgwA0uJiqZ/on8icn+04mx9zL4n9Pol9mR0c9w+ZZsAqP+YS97JT0WAPjktic/AvSezYDrKoC7afm1s1b2io+cWSexzbc53b3Xp/lRlO9uyNmkcerCLi/Pnp62KIVNtjhpkXdu1qOYeZb34U9s4Bfn9YHhF2/9lxcV+faRnUuDUnzzSV+zrIRe/AhRCiULSACyFEoWgBF0KIQmm5gJvZKWZ2n5ltMbPHzOwjVfwzZrbdzDZWX++Y+nSFEEIcJkfEHAHwMXd/2MwWAthgZndVP7vG3f+w/rRi3y3W8D4Vw9qGCZZvIbGTSOwnw/jbZM73SCx6lXJ5FYn9LxJjRqQt0eCwj0zKFTFZVbVo0Ejbsy1OKk0CwCtJjPW++0HrtGqEGVUWLkxNIqzF1kAQ5Zh4xY5j12SVAOO8l4hRhdFLDDmxfV03MaUw4W54KBUBmXAaBV0mkvaQx8iI7d8A4ODLzWJhbIsG8PvP7nWEmahYjJ+/PcF1MuR05NmBqtmku+83s63gS5kQQohpZFJ74GZ2GoBz8eP3dx82s01mdq2ZddadUwghxKTIXsDN7BgANwP4qLvvA/B5AGcAWIXGO/Q/muC41Wa23szWDw4O1pCyEEIIIHMBN7NuNBbvr7r7LQDg7s+7+6i7jwH4IoDz2bHuvs7d+929v6+vr668hRDiqKflHriZGYAvAdjq7p8bF19R7Y8DwLsBbK4vra+E8VvJHNbOiTnW4kNckU5hxQ5TExhwC4lF7WI7mfOXJHYOib2HxO4IY1bMj3WXO0BiWf7G75PYsyTGRMw3h/GnMq43EX9HYrEf3gYy50ISey2JPdMyAyYe8nmpMBgrAeZWHmRF7XjLtubXPxPHFi9Kq03u258K1/H884jrklU/ZCIgrfAX5jHBkp2LPe7e3lQsfPlg803LdTvmuizb5RBp/5YjnE6GnE+hvBHABwA8amYbq9gnAVxhZqsAOBq/4R+qNTMhhBBHJOdTKPcDMPKjb9SfjhBCiFzkxBRCiELRAi6EEIUyS8vJvi6MozMT4CpjtEUCSJx/qUsL+4n7MOplE5E7L/JvxAX5BSIynhfGD7OTMXdXKqAkaqeR6zkTOtnLpEYvF9ug8/eSYGyjdxmZc24a+olTybzPtMqKCnKsxCwjuix7xlKhc+QQKVc7mgpwLI8IK/faRxyPTMSM7szuuenzvWDBMUmMCX4j5P7EGHuMPb1EECXn4q3dmvNgTkn2mJgTNtJJ+deusakVSQG9AxdCiGLRAi6EEIWiBVwIIQpFC7gQQhTKLBUx7wrjp8kcIlYxgRI7w3gRmfN6EmMuvBwX1b+SWK7gSgREKlpGWO/D1IWX4DnnBrhgye51dGdmlvzNzuM/h/EOMocIljeSaRniMxPDGExkjG5D5mQcI47EHMESAOZ0Nb/3YmVih4k7k4mR0ZHIxD0mKNJyqcGBCqS9IZkbMUdQBLiomCM0xvsFcAftaBBY+fWYC5xckzpo1RNTCCEEtIALIUSxaAEXQohCmaV74JGnSIxVzWNl+aKR5yIyh/RPSztn8Qp/yf4t25dle+enk1gOrA0a2+8mrbNqhbVei9UB2fNxJomxeYy4p/sdMidqHgAWxr3zPJj5I/dXJu5lsz3euaT0IIuxPde4fxvblgG8/Rjbi8/hENmb7yaPKXd/OJK/95/XuiyHuN/NYI+n7n3sTtA7cCGEKBQt4EIIUShawIUQolBaLuBmNs/MHjSzR8zsMTNbW8VXmtkDZvaUmX3NzPLalwghhKiFHEVmCMDF7n6g6o15v5l9E8CvA7jG3W80sy8AuAqNRsc1cEoYs1ZpPySx40ksGk4eIHOIGLafGYUYUeRgx7UrWDJy2qLNFNHs8SiZw0xNF5EYe84fCuPYeg+gVRh/I/alA/duBZj5gwlmtLVYrMBHhK/8NmLpe6OeIGIyQY4UKGzbvJILE2EXhKqI1BxD8mf3n8EqMeacnz8nc1rOYefKJdewlEvLO+QNDn/+orv6cgAXA7ipil8P4F21ZiaEEOKI5Hal76r6Ye5Cw+f+NIA97n747c42TFAg2sxWm9l6M1s/ODhYR85CCCGQuYC7+6i7rwJwMoDzkX64+kjHrnP3fnfv7+vrazNNIYQQkUl9CsXd9wC4D8AbACw2s8MbOicD2F5zbkIIIY5Ayx11MzsewCF332Nm8wFcAuAP0FjIfwGNWm9XAritvrTeHMabM487kcSiqMUEiGtJbCWJsdZcUYi6mMw5WogCa1qZjjtoN5EYq3Z4S9Pov5GX3JPkqLvvJO8tMkRMKqxRETON5QhruTCxM1YQZNcbI23c+PlHwzi9Xq4jsYsIj93dzbkxoZPBqilysbb5/MyVyh4TE4cj7DGOJGJ9vpO0bhEz52wrAFxvZl1ovGP/urvfYWZbANxoZv8TjY9xfKnWzIQQQhyRlgu4u28C+Wycuz+Dxn64EEKIGUBOTCGEKBQt4EIIUSiztJzsz4RxKhqkbdcA7lKM5TOZiMYEiFgaFeBlT6N4VJ94VTs5z3aeFjMBUTxKxSTuxGT3jJUlfaZpxATLM3BCGlxELQptMUxahrFYbKnGhDsm+DGYgBhbl+W2PIsOTgAYHooiJmsFllcmlomM8Xy5DksGL2HbfM1ckZS1f8sht3xtu2VuJ4PegQshRKFoARdCiELRAi6EEIWiBVwIIQpldoqYN4fxE5elc75KYszMvyKMlwykc/buTmMHSe/Js17T+vzHkRyWZeQ1EVGbYtoqazPJenpGSPtIPEhiTPeNlV0BALH3JBMsmcP1EhJjQtTSptHd7LhXfCCNPU5O9ackFjg0kiq6w8Tld4gIiF0Dzc6/ecQpGd2UADDK3I1UjGwWSQcG0td1rhuU9buMMEdiTk9Jei5yHHNd5uSVCxN5c0RM1heVCcHx+QC4+7Nu9A5cCCEKRQu4EEIUihZwIYQoFHP3abvYiSee6KtXr5626wkhxP8PrF27doO798e43oELIUShaAEXQohC0QIuhBCF0nIBN7N5ZvagmT1iZo+Z2doqfp2Zfc/MNlZfq6Y+XSGEEIfJMfIMAbjY3Q+YWTeA+83sm9XPftPdb5q69IQQQkxETkceB3CgGnZXX9P30RUhhBCUrD1wM+sys40AdgG4y90fqH70u2a2ycyuMTPaQdXMVpvZejNbPzg4WFPaQgghshZwdx9191UATgZwvpn9JIBPADgLwOvQKFLx8QmOXefu/e7e39fXV1PaQgghJvUpFHffA+A+AJe6+w5vMATgy1CDYyGEmFZaOjHN7HgAh9x9j5nNB/AtAH8AYIO77zAzA3ANgJfdfU2Lc72ARm2748BL1ZWC8p9ZlP/MUXLuQLn5n+rux8dgzqdQVgC43sy60HjH/nV3v8PM7q0WdwOwEcCvtDrR4QTMbD2zhZaC8p9ZlP/MUXLuQPn5R3I+hbIJwLkkfvGUZCSEECILOTGFEKJQZmoBXzdD160L5T+zKP+Zo+TcgfLzb2Jay8kKIYSoD22hCCFEoUz7Am5ml5rZ42b2lJkd8WOHswEzu9bMdpnZ5nGxpWZ2l5k9Wf27ZCZznAgzO8XM7jOzLVUhso9U8VLyn6iQ2koze6B6DX3NzNKOsrOIysn8HTO7oxoXk7+ZPWtmj1YF69ZXsSJePwBgZovN7CYz+66ZbTWzN5SUfyumdQGvPor45wDeDuBsAFeY2dnTmUMbXAfg0hBbA+Aed38VgHuq8WxkBMDH3P1sAK8H8KvV/S4l/8OF1M4BsArApWb2ejR8CNe4+ysBvATgqhnMMYePANg6blxa/m9x91XjPn5XyusHAP4EwD+6+1kAzkHjeSgp/yPj7tP2BeANAO4cN/4EgE9MZw5t5n0agM3jxo8DWFF9vwLA4zOdY+bjuA3AJSXmD6APwMMALkDDiDGXvaZm2xca5SfuAXAxgDvQ8E2UlP+zAI4LsSJePwAWAfgeKq2vtPxzvqZ7C+UkAM+NG2+rYqWx3N13VN/vBLB8JpPJwcxOQ+Pz/A+goPxjITUATwPY4+4j1ZTZ/hr6YwC/BWCsGr8CZeXvAL5lZhvM7HBD21JePysBvADgy9UW1l+Z2QKUk39LJGJ2iDf+jM/qj/KY2TEAbgbwUXffN/5nsz1/D4XU0CigVgRmdhmAXe6+YaZz6YA3uft5aGx7/qqZXTj+h7P89TMXwHkAPu/u5wIYQNgumeX5t2S6FxbSa5cAAAGTSURBVPDtAE4ZNz65ipXG82a2AgCqf3fNcD4TUjXhuBnAV939lipcTP6H8R8XUnsDgMVmdthFPJtfQ28E8HNm9iyAG9HYRvkTlJM/3H179e8uALei8Ue0lNfPNgDb/Mflr29CY0EvJf+WTPcC/hCAV1UqfA+A9wG4fZpzqIPbAVxZfX8lGnvLs46q0NiXAGx198+N+1Ep+R9vZour7+ejsX+/FY2F/BeqabM2f3f/hLuf7O6nofFav9fd349C8jezBWa28PD3AH4awGYU8vpx950AnjOzV1ehtwLYgkLyz2IGhIV3AHgCjb3MT820CJCR7w0AdgA4hMZf9KvQ2Me8B8CTAO4GsHSm85wg9zeh8d/DTWgUHNtY3f9S8v9PAL5T5b8ZwO9U8dMBPAjgKQB/B6B3pnPNeCwXAbijpPyrPB+pvh47/PtayuunynUVgPXVa+jvASwpKf9WX3JiCiFEoUjEFEKIQtECLoQQhaIFXAghCkULuBBCFIoWcCGEKBQt4EIIUShawIUQolC0gAshRKH8X09qus/w9hT5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            " frog  deer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2E6ASOUo7PV"
      },
      "source": [
        "### ResNet18 for CIFAR10 define ###\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import os\r\n",
        "# https://raw.githubusercontent.com/huyvnphan/PyTorch_CIFAR10/master/cifar10_models/resnet.py\r\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\r\n",
        "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d']\r\n",
        "\r\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\r\n",
        "  \"\"\"3x3 convolution with padding\"\"\"\r\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\r\n",
        "                    padding=dilation, groups=groups, bias=False, dilation=dilation)\r\n",
        "\r\n",
        "\r\n",
        "def conv1x1(in_planes, out_planes, stride=1):\r\n",
        "  \"\"\"1x1 convolution\"\"\"\r\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\r\n",
        "\r\n",
        "\r\n",
        "class BasicBlock(nn.Module):\r\n",
        "  expansion = 1\r\n",
        "\r\n",
        "  def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\r\n",
        "                base_width=64, dilation=1, norm_layer=None):\r\n",
        "    super(BasicBlock, self).__init__()\r\n",
        "    if norm_layer is None:\r\n",
        "      norm_layer = nn.BatchNorm2d\r\n",
        "    if groups != 1 or base_width != 64:\r\n",
        "      raise ValueError('BasicBlock only supports groups=1 and base_width=64')\r\n",
        "    if dilation > 1:\r\n",
        "      raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\r\n",
        "    # Both self.conv1 and self.downsample layers downsample the input when stride != 1\r\n",
        "    self.conv1 = conv3x3(inplanes, planes, stride)\r\n",
        "    self.bn1 = norm_layer(planes)\r\n",
        "    self.relu = nn.ReLU(inplace=True)\r\n",
        "    self.conv2 = conv3x3(planes, planes)\r\n",
        "    self.bn2 = norm_layer(planes)\r\n",
        "    self.downsample = downsample\r\n",
        "    self.stride = stride\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    identity = x\r\n",
        "\r\n",
        "    out = self.conv1(x)\r\n",
        "    out = self.bn1(out)\r\n",
        "    out = self.relu(out)\r\n",
        "\r\n",
        "    out = self.conv2(out)\r\n",
        "    out = self.bn2(out)\r\n",
        "\r\n",
        "    if self.downsample is not None:\r\n",
        "        identity = self.downsample(x)\r\n",
        "\r\n",
        "    out += identity\r\n",
        "    out = self.relu(out)\r\n",
        "\r\n",
        "    return out\r\n",
        "\r\n",
        "\r\n",
        "class Bottleneck(nn.Module):\r\n",
        "  expansion = 4\r\n",
        "\r\n",
        "  def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\r\n",
        "                base_width=64, dilation=1, norm_layer=None):\r\n",
        "    super(Bottleneck, self).__init__()\r\n",
        "    if norm_layer is None:\r\n",
        "        norm_layer = nn.BatchNorm2d\r\n",
        "    width = int(planes * (base_width / 64.)) * groups\r\n",
        "    # Both self.conv2 and self.downsample layers downsample the input when stride != 1\r\n",
        "    self.conv1 = conv1x1(inplanes, width)\r\n",
        "    self.bn1 = norm_layer(width)\r\n",
        "    self.conv2 = conv3x3(width, width, stride, groups, dilation)\r\n",
        "    self.bn2 = norm_layer(width)\r\n",
        "    self.conv3 = conv1x1(width, planes * self.expansion)\r\n",
        "    self.bn3 = norm_layer(planes * self.expansion)\r\n",
        "    self.relu = nn.ReLU(inplace=True)\r\n",
        "    self.downsample = downsample\r\n",
        "    self.stride = stride\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "      identity = x\r\n",
        "\r\n",
        "      out = self.conv1(x)\r\n",
        "      out = self.bn1(out)\r\n",
        "      out = self.relu(out)\r\n",
        "\r\n",
        "      out = self.conv2(out)\r\n",
        "      out = self.bn2(out)\r\n",
        "      out = self.relu(out)\r\n",
        "\r\n",
        "      out = self.conv3(out)\r\n",
        "      out = self.bn3(out)\r\n",
        "\r\n",
        "      if self.downsample is not None:\r\n",
        "          identity = self.downsample(x)\r\n",
        "\r\n",
        "      out += identity\r\n",
        "      out = self.relu(out)\r\n",
        "\r\n",
        "      return out\r\n",
        "\r\n",
        "\r\n",
        "class ResNet(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, block, layers, num_classes=10, zero_init_residual=False,\r\n",
        "                groups=1, width_per_group=64, replace_stride_with_dilation=None,\r\n",
        "                norm_layer=None):\r\n",
        "    super(ResNet, self).__init__()\r\n",
        "    if norm_layer is None:\r\n",
        "      norm_layer = nn.BatchNorm2d\r\n",
        "    self._norm_layer = norm_layer\r\n",
        "\r\n",
        "    self.inplanes = 64\r\n",
        "    self.dilation = 1\r\n",
        "    if replace_stride_with_dilation is None:\r\n",
        "      # each element in the tuple indicates if we should replace\r\n",
        "      # the 2x2 stride with a dilated convolution instead\r\n",
        "      replace_stride_with_dilation = [False, False, False]\r\n",
        "    if len(replace_stride_with_dilation) != 3:\r\n",
        "      raise ValueError(\"replace_stride_with_dilation should be None \"\r\n",
        "                        \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\r\n",
        "    self.groups = groups\r\n",
        "    self.base_width = width_per_group\r\n",
        "    \r\n",
        "    ## CIFAR10: kernel_size 7 -> 3, stride 2 -> 1, padding 3->1\r\n",
        "    self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\r\n",
        "    ## END\r\n",
        "    \r\n",
        "    self.bn1 = norm_layer(self.inplanes)\r\n",
        "    self.relu = nn.ReLU(inplace=True)\r\n",
        "    # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
        "    self.layer1 = self._make_layer(block, 64, layers[0])\r\n",
        "    self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\r\n",
        "                                    dilate=replace_stride_with_dilation[0])\r\n",
        "    self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\r\n",
        "                                    dilate=replace_stride_with_dilation[1])\r\n",
        "    self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\r\n",
        "                                    dilate=replace_stride_with_dilation[2])\r\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\r\n",
        "    self.fc = nn.Linear(512 * block.expansion, num_classes)\r\n",
        "\r\n",
        "    for m in self.modules():\r\n",
        "      if isinstance(m, nn.Conv2d):\r\n",
        "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n",
        "      elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\r\n",
        "        nn.init.constant_(m.weight, 1)\r\n",
        "        nn.init.constant_(m.bias, 0)\r\n",
        "\r\n",
        "    # Zero-initialize the last BN in each residual branch,\r\n",
        "    # so that the residual branch starts with zeros, and each residual block behaves like an identity.\r\n",
        "    # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\r\n",
        "    if zero_init_residual:\r\n",
        "      for m in self.modules():\r\n",
        "        if isinstance(m, Bottleneck):\r\n",
        "          nn.init.constant_(m.bn3.weight, 0)\r\n",
        "        elif isinstance(m, BasicBlock):\r\n",
        "          nn.init.constant_(m.bn2.weight, 0)\r\n",
        "\r\n",
        "  def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\r\n",
        "    norm_layer = self._norm_layer\r\n",
        "    downsample = None\r\n",
        "    previous_dilation = self.dilation\r\n",
        "    if dilate:\r\n",
        "        self.dilation *= stride\r\n",
        "        stride = 1\r\n",
        "    if stride != 1 or self.inplanes != planes * block.expansion:\r\n",
        "        downsample = nn.Sequential(\r\n",
        "            conv1x1(self.inplanes, planes * block.expansion, stride),\r\n",
        "            norm_layer(planes * block.expansion),\r\n",
        "        )\r\n",
        "\r\n",
        "    layers = []\r\n",
        "    layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\r\n",
        "                        self.base_width, previous_dilation, norm_layer))\r\n",
        "    self.inplanes = planes * block.expansion\r\n",
        "    for _ in range(1, blocks):\r\n",
        "        layers.append(block(self.inplanes, planes, groups=self.groups,\r\n",
        "                            base_width=self.base_width, dilation=self.dilation,\r\n",
        "                            norm_layer=norm_layer))\r\n",
        "\r\n",
        "    return nn.Sequential(*layers)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.conv1(x)\r\n",
        "    x = self.bn1(x)\r\n",
        "    x = self.relu(x)\r\n",
        "    # x = self.maxpool(x)\r\n",
        "\r\n",
        "    x = self.layer1(x)\r\n",
        "    x = self.layer2(x)\r\n",
        "    x = self.layer3(x)\r\n",
        "    x = self.layer4(x)\r\n",
        "\r\n",
        "    x = self.avgpool(x)\r\n",
        "    x = x.reshape(x.size(0), -1)\r\n",
        "    x = self.fc(x)\r\n",
        "\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "def _resnet(arch, block, layers, pretrained, progress, device, **kwargs):\r\n",
        "  model = ResNet(block, layers, **kwargs)\r\n",
        "  if pretrained:\r\n",
        "      script_dir = os.path.dirname(__file__)\r\n",
        "      state_dict = torch.load(script_dir + '/state_dicts/'+arch+'.pt', map_location=device)\r\n",
        "      model.load_state_dict(state_dict)\r\n",
        "  return model\r\n",
        "\r\n",
        "\r\n",
        "def resnet18(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNet-18 model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress, device,\r\n",
        "                  **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnet34(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNet-34 model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress, device,\r\n",
        "                  **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnet50(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNet-50 model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress, device,\r\n",
        "                  **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnet101(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNet-101 model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress, device,\r\n",
        "                  **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnet152(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNet-152 model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress, device,\r\n",
        "                  **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnext50_32x4d(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNeXt-50 32x4d model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  kwargs['groups'] = 32\r\n",
        "  kwargs['width_per_group'] = 4\r\n",
        "  return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3],\r\n",
        "                  pretrained, progress, device, **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnext101_32x8d(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNeXt-101 32x8d model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  kwargs['groups'] = 32\r\n",
        "  kwargs['width_per_group'] = 8\r\n",
        "  return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\r\n",
        "                  pretrained, progress, device, **kwargs)\r\n",
        "\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh_OjbkTKGV-"
      },
      "source": [
        "### resnet call ###\r\n",
        "import copy\r\n",
        "import torch.nn as nn\r\n",
        "from torchvision import models\r\n",
        "\r\n",
        "if args.resnet_version is not None:\r\n",
        "  resnet = eval(f'{args.resnet_version}()')\r\n",
        "\r\n",
        "  resnet.output_dim = resnet.fc.in_features\r\n",
        "  resnet.fc = nn.Identity()\r\n",
        "else:\r\n",
        "  raise NotImplementedError(\"Backbone is not implemented!\")\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDkTLBPcy1lv"
      },
      "source": [
        "### siambyol network define ###\r\n",
        "import math\r\n",
        "from torch.nn import functional\r\n",
        "\r\n",
        "hidden_size=4096\r\n",
        "projection_size=256\r\n",
        "\r\n",
        "class MLP(nn.Module):\r\n",
        "  def __init__(self, input_dim):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.net = nn.Sequential(\r\n",
        "        nn.Linear(input_dim, hidden_size), \r\n",
        "        nn.BatchNorm1d(hidden_size, momentum=1-0.9, eps=1e-5), \r\n",
        "        nn.ReLU(inplace=True), \r\n",
        "        nn.Linear(hidden_size, projection_size)\r\n",
        "    )\r\n",
        "  def forward(self, x):\r\n",
        "    return self.net(x)\r\n",
        "\r\n",
        "class BYOL(nn.Module):\r\n",
        "  def __init__(self, backbone):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.backbone=backbone\r\n",
        "    self.projector = MLP(backbone.output_dim)\r\n",
        "    self.online_encoder = nn.Sequential(\r\n",
        "        self.backbone, \r\n",
        "        self.projector,\r\n",
        "    )\r\n",
        "    self.predictor = MLP(projection_size)\r\n",
        "    self.target_encoder = copy.deepcopy(self.online_encoder)\r\n",
        "\r\n",
        "  def target_ema(self, k, K, base_tau=0.996):\r\n",
        "    return 1-(1-base_tau)*(math.cos(math.pi*k/K)+1)/2\r\n",
        "\r\n",
        "  def update_moving_average(self, global_step, max_steps):\r\n",
        "    tau = self.target_ema(global_step, max_steps)\r\n",
        "    for online, target in zip(self.online_encoder.parameters(), self.target_encoder.parameters()):\r\n",
        "      target.data = tau*target.data + (1-tau)*online.data\r\n",
        "  \r\n",
        "  def loss_function(self, p, z):\r\n",
        "    p=functional.normalize(p, dim=-1, p=2)\r\n",
        "    z=functional.normalize(z, dim=-1, p=2)\r\n",
        "    return 2 - 2*(p*z).sum(dim=-1)\r\n",
        "\r\n",
        "  def forward(self, x1, x2):\r\n",
        "    z1_online, z2_online = self.online_encoder(x1), self.online_encoder(x2)\r\n",
        "    p1_online, p2_online = self.predictor(z1_online), self.predictor(z2_online)\r\n",
        "    with torch.no_grad():\r\n",
        "      z1_target, z2_target = self.target_encoder(x1), self.target_encoder(x2)\r\n",
        "    \r\n",
        "    loss1, loss2 = self.loss_function(p1_online, z2_target.detach()), self.loss_function(p2_online, z1_target.detach())\r\n",
        "\r\n",
        "    loss = loss1+loss2\r\n",
        "    return loss.mean()\r\n",
        "\r\n",
        "class SiamBYOL(nn.Module):\r\n",
        "  def __init__(self, backbone):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.backbone=backbone\r\n",
        "    self.projector = MLP(backbone.output_dim)\r\n",
        "    self.online_encoder = nn.Sequential(\r\n",
        "        self.backbone, \r\n",
        "        self.projector,\r\n",
        "    )\r\n",
        "    self.predictor = MLP(projection_size)\r\n",
        "  \r\n",
        "  def set_target(self, model):\r\n",
        "    target_encoder = copy.deepcopy(model)\r\n",
        "    return target_encoder\r\n",
        "  \r\n",
        "  def loss_function(self, p, z):\r\n",
        "    p=functional.normalize(p, dim=-1, p=2)\r\n",
        "    z=functional.normalize(z, dim=-1, p=2)\r\n",
        "    return 2 - 2*(p*z).sum(dim=-1)\r\n",
        "\r\n",
        "  def forward(self, x1, x2, target):\r\n",
        "    z1_online, z2_online = self.online_encoder(x1), self.online_encoder(x2)\r\n",
        "    p1_online, p2_online = self.predictor(z1_online), self.predictor(z2_online)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      target_encoder = self.set_target(target)\r\n",
        "      z1_target, z2_target = target_encoder(x1), target_encoder(x2)\r\n",
        "    \r\n",
        "    loss1, loss2 = self.loss_function(p1_online, z2_target.detach()), self.loss_function(p2_online, z1_target.detach())\r\n",
        "\r\n",
        "    loss = loss1+loss2\r\n",
        "    return loss.mean()\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoNT2XuVRa_t"
      },
      "source": [
        "### byol network call ###\r\n",
        "byol = BYOL(resnet)\r\n",
        "\r\n",
        "# model load, check 'pre model path' to load pre model\r\n",
        "if args.current_epochs != 0:\r\n",
        "  pre_model = torch.load('')\r\n",
        "  msg = byol.load_state_dict(pre_model['state_dict'])\r\n",
        "  print(msg)\r\n",
        "\r\n",
        "byol = byol.to(args.device)\r\n",
        "byol = torch.nn.DataParallel(byol)\r\n",
        "\r\n",
        "siambyol = SiamBYOL(resnet)\r\n",
        "\r\n",
        "# model load, check 'pre model path' to load pre model\r\n",
        "if args.current_epochs != 0:\r\n",
        "  pre_model = torch.load('')\r\n",
        "  msg = siambyol.load_state_dict(pre_model['state_dict'])\r\n",
        "  print(msg)\r\n",
        "\r\n",
        "siambyol = siambyol.to(args.device)\r\n",
        "siambyol = torch.nn.DataParallel(siambyol)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VonOn4aaUCV2"
      },
      "source": [
        "### optimizer call ###\r\n",
        "from torch.optim import SGD\r\n",
        "\r\n",
        "predictor_prefix = ('module.predictor', 'predictor')\r\n",
        "byol_parameters = [{\r\n",
        "    'name': 'base',\r\n",
        "    'params': [param for name, param in byol.named_parameters() if not name.startswith(predictor_prefix)],\r\n",
        "    'lr': args.learning_rate\r\n",
        "},{\r\n",
        "    'name': 'predictor',\r\n",
        "    'params': [param for name, param in byol.named_parameters() if name.startswith(predictor_prefix)],\r\n",
        "    'lr': args.learning_rate\r\n",
        "}]\r\n",
        "siambyol_parameters = [{\r\n",
        "    'name': 'base',\r\n",
        "    'params': [param for name, param in siambyol.named_parameters() if not name.startswith(predictor_prefix)],\r\n",
        "    'lr': args.learning_rate\r\n",
        "},{\r\n",
        "    'name': 'predictor',\r\n",
        "    'params': [param for name, param in siambyol.named_parameters() if name.startswith(predictor_prefix)],\r\n",
        "    'lr': args.learning_rate\r\n",
        "}]\r\n",
        "\r\n",
        "byol_optimizer = SGD(byol_parameters, lr=args.learning_rate*args.batch_size/256, momentum=0.9)\r\n",
        "siambyol_optimizer = SGD(siambyol_parameters, lr=args.learning_rate*args.batch_size/256, momentum=0.9)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dELIoWzCuZt4"
      },
      "source": [
        "### learning rate scheduler define ###\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "class LR_Scheduler(object):\r\n",
        "  def __init__(self, optimizer, warmup_epochs, warmup_lr, num_epochs, base_lr, final_lr, iter_per_epoch, constant_predictor_lr=False):\r\n",
        "    self.base_lr = base_lr\r\n",
        "    self.constant_predictor_lr = constant_predictor_lr\r\n",
        "    warmup_iter = iter_per_epoch * warmup_epochs\r\n",
        "    warmup_lr_schedule = np.linspace(warmup_lr, base_lr, warmup_iter)\r\n",
        "    decay_iter = iter_per_epoch * (num_epochs - warmup_epochs)\r\n",
        "    cosine_lr_schedule = final_lr+0.5*(base_lr-final_lr)*(1+np.cos(np.pi*np.arange(decay_iter)/decay_iter))\r\n",
        "    \r\n",
        "    self.lr_schedule = np.concatenate((warmup_lr_schedule, cosine_lr_schedule))\r\n",
        "    self.optimizer = optimizer\r\n",
        "    self.iter = 0\r\n",
        "    self.current_lr = 0\r\n",
        "  def step(self):\r\n",
        "    for param_group in self.optimizer.param_groups:\r\n",
        "\r\n",
        "      if self.constant_predictor_lr and param_group['name'] == 'predictor':\r\n",
        "        param_group['lr'] = self.base_lr\r\n",
        "      else:\r\n",
        "        lr = param_group['lr'] = self.lr_schedule[self.iter]\r\n",
        "    \r\n",
        "    self.iter += 1\r\n",
        "    self.current_lr = lr\r\n",
        "    return lr\r\n",
        "  def get_lr(self):\r\n",
        "    return self.current_lr\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHd0qVZ_JYW9"
      },
      "source": [
        "### lr_scheduler define ###\r\n",
        "byol_lr_scheduler = LR_Scheduler(byol_optimizer, args.warmup_epochs, 0, args.num_epochs, args.learning_rate*args.batch_size/256, 0, len(train_loader), constant_predictor_lr=True)\r\n",
        "siambyol_lr_scheduler = LR_Scheduler(siambyol_optimizer, args.warmup_epochs, 0, args.num_epochs, args.learning_rate*args.batch_size/256, 0, len(train_loader), constant_predictor_lr=True)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur2YMpd2Vi-U",
        "outputId": "e8d4d1a6-eafe-45c6-a7cb-085e6a1b53d0"
      },
      "source": [
        "### Training ###\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "from collections import defaultdict\r\n",
        "from datetime import datetime\r\n",
        "from tqdm import tqdm\r\n",
        "import os\r\n",
        "\r\n",
        "writer = SummaryWriter()\r\n",
        "\r\n",
        "global_step = 0\r\n",
        "for epoch in tqdm(range(args.current_epochs, args.num_epochs), desc=f'Training'):\r\n",
        "  metrics = defaultdict(list)\r\n",
        "  \r\n",
        "  for step, ((x1, x2), labels) in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{args.num_epochs}')):\r\n",
        "    x1, x2 = x1.cuda(non_blocking=True), x2.cuda(non_blocking=True)\r\n",
        "\r\n",
        "    byol_loss = byol(x1, x2)\r\n",
        "    byol_optimizer.zero_grad()\r\n",
        "    byol_loss.backward()\r\n",
        "    byol_optimizer.step()\r\n",
        "    byol_lr_scheduler.step() # defined scheduler\r\n",
        "    byol.module.update_moving_average(step+1, len(train_loader))\r\n",
        "\r\n",
        "    siambyol_loss = siambyol(x1, x2, byol.module.online_encoder)\r\n",
        "    siambyol_optimizer.zero_grad()\r\n",
        "    siambyol_loss.backward()\r\n",
        "    siambyol_optimizer.step()\r\n",
        "    siambyol_lr_scheduler.step()\r\n",
        "    \r\n",
        "    writer.add_scalar(\"Loss/train_step\", siambyol_loss, global_step)\r\n",
        "    metrics[\"Loss/train\"].append(siambyol_loss.item())\r\n",
        "    global_step += 1\r\n",
        "  \r\n",
        "  for k, v in metrics.items():\r\n",
        "    writer.add_scalar(k, np.array(v).mean(), epoch+1)\r\n",
        "\r\n",
        "  if (epoch+1)%args.checkpoint_epochs == 0:\r\n",
        "    byol_ckpt_path = os.path.join(tmp_dir, f\"byol_{args.optim}_{epoch+1}.pt\")\r\n",
        "    print(f'Saving model at epoch {epoch+1}')\r\n",
        "    torch.save({\r\n",
        "        'epoch':epoch+1, \r\n",
        "        'state_dict':byol.module.state_dict()\r\n",
        "    }, byol_ckpt_path)\r\n",
        "    siambyol_ckpt_path = os.path.join(tmp_dir, f\"siambyol_{args.optim}_{epoch+1}.pt\")\r\n",
        "    print(f'Saving model at epoch {epoch+1}')\r\n",
        "    torch.save({\r\n",
        "        'epoch':epoch+1, \r\n",
        "        'state_dict':siambyol.module.state_dict()\r\n",
        "    }, siambyol_ckpt_path)\r\n",
        "\r\n",
        "byol_ckpt_path = os.path.join(tmp_dir, f\"byol_{args.optim}_final.pt\")\r\n",
        "print(f'Saving final model at epoch {epoch+1}')\r\n",
        "torch.save({\r\n",
        "    'epoch':epoch+1, \r\n",
        "    'state_dict':byol.module.state_dict()\r\n",
        "}, byol_ckpt_path)\r\n",
        "siambyol_ckpt_path = os.path.join(tmp_dir, f\"siambyol_{args.optim}_final.pt\")\r\n",
        "print(f'Saving final model at epoch {epoch+1}')\r\n",
        "torch.save({\r\n",
        "    'epoch':epoch+1, \r\n",
        "    'state_dict':siambyol.module.state_dict()\r\n",
        "}, siambyol_ckpt_path)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 1/1:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1/1:  25%|██▌       | 1/4 [00:00<00:00,  7.85it/s]\u001b[A\n",
            "Epoch 1/1:  50%|█████     | 2/4 [00:00<00:00,  7.84it/s]\u001b[A\n",
            "Epoch 1/1:  75%|███████▌  | 3/4 [00:00<00:00,  7.81it/s]\u001b[A\n",
            "Epoch 1/1: 100%|██████████| 4/4 [00:00<00:00,  7.70it/s]\n",
            "Training: 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving final model at epoch 1\n",
            "Saving final model at epoch 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRogCvo2Wu_2"
      },
      "source": [
        "### Linear Evaluation define ###\r\n",
        "import torch.nn.functional as F \r\n",
        "\r\n",
        "class AverageMeter():\r\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\r\n",
        "    def __init__(self, name, fmt=':f'):\r\n",
        "        self.name = name\r\n",
        "        self.fmt = fmt\r\n",
        "        self.log = []\r\n",
        "        self.val = 0\r\n",
        "        self.avg = 0\r\n",
        "        self.sum = 0\r\n",
        "        self.count = 0\r\n",
        "\r\n",
        "    def reset(self):\r\n",
        "        self.log.append(self.avg)\r\n",
        "        self.val = 0\r\n",
        "        self.avg = 0\r\n",
        "        self.sum = 0\r\n",
        "        self.count = 0\r\n",
        "\r\n",
        "    def update(self, val, n=1):\r\n",
        "        self.val = val\r\n",
        "        self.sum += val * n\r\n",
        "        self.count += n\r\n",
        "        self.avg = self.sum / self.count\r\n",
        "\r\n",
        "    def __str__(self):\r\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\r\n",
        "        return fmtstr.format(**self.__dict__)\r\n",
        "\r\n",
        "def linear_eval(args, eval_from):\r\n",
        "  eval_train_loader = torch.utils.data.DataLoader(\r\n",
        "      torchvision.datasets.CIFAR10(\r\n",
        "          root=args.dataset_dir, \r\n",
        "          train=True, \r\n",
        "          download=False, \r\n",
        "          transform=Transform_single(size=args.image_size, train=True), \r\n",
        "      ), \r\n",
        "      shuffle=True,\r\n",
        "      batch_size=args.batch_size,\r\n",
        "      num_workers=args.num_workers,\r\n",
        "      drop_last=True,\r\n",
        "      pin_memory=True,\r\n",
        "  )\r\n",
        "\r\n",
        "  eval_test_loader = torch.utils.data.DataLoader(\r\n",
        "      torchvision.datasets.CIFAR10(\r\n",
        "          root=args.dataset_dir, \r\n",
        "          train=False, \r\n",
        "          download=False, \r\n",
        "          transform=Transform_single(size=args.image_size, train=False), \r\n",
        "      ), \r\n",
        "      shuffle=False,\r\n",
        "      batch_size=args.batch_size,\r\n",
        "      num_workers=args.num_workers,\r\n",
        "      drop_last=True,\r\n",
        "      pin_memory=True,\r\n",
        "  )\r\n",
        "\r\n",
        "  eval_model = eval(f\"{args.resnet_version}()\")\r\n",
        "  # eval_model = eval(f\"model.{args.resnet_version}()\")\r\n",
        "  eval_model.output_dim = eval_model.fc.in_features\r\n",
        "  eval_model.fc = torch.nn.Identity()\r\n",
        "  eval_classifier = nn.Linear(in_features=eval_model.output_dim, out_features=10, bias=True).to(args.device)\r\n",
        "\r\n",
        "  ###\r\n",
        "  assert eval_from is not None\r\n",
        "  eval_save_dict = torch.load(eval_from, map_location='cuda')\r\n",
        "  eval_msg = eval_model.load_state_dict({k[9:]:v for k, v in eval_save_dict['state_dict'].items() if k.startswith('backbone.')}, strict=True)\r\n",
        "  \r\n",
        "  print(eval_msg)\r\n",
        "  eval_model = eval_model.to(args.device)\r\n",
        "  eval_model = torch.nn.DataParallel(eval_model)\r\n",
        "\r\n",
        "  # if torch.cuda.device_count() > 1: eval_classifier = torch.nn.SyncBatchNorm.convert_sync_batchnorm(eval_classifier)\r\n",
        "  eval_classifier = torch.nn.DataParallel(eval_classifier)\r\n",
        "  # define optimizer 'sgd', eval_classifier, lr=eval_base_lr=30, momentum=eval_optim_momentum-0.9, weight_decay=eval_optim_weight_decay=0\r\n",
        "  predictor_prefix = ('module.predictor', 'predictor')\r\n",
        "  parameters = [{\r\n",
        "      'name': 'base',\r\n",
        "      'params': [param for name, param in eval_classifier.named_parameters() if not name.startswith(predictor_prefix)],\r\n",
        "      'lr': 30\r\n",
        "  },{\r\n",
        "      'name': 'predictor',\r\n",
        "      'params': [param for name, param in eval_classifier.named_parameters() if name.startswith(predictor_prefix)],\r\n",
        "      'lr': 30\r\n",
        "  }]\r\n",
        "  eval_optimizer = torch.optim.SGD(parameters, lr=30, momentum=0.9, weight_decay=0)\r\n",
        "\r\n",
        "  # define lr scheduler\r\n",
        "  eval_lr_scheduler = LR_Scheduler(\r\n",
        "      eval_optimizer,\r\n",
        "      0, 0*args.batch_size/256, \r\n",
        "      30, 30*args.batch_size/256, 0*args.batch_size/256, \r\n",
        "      len(eval_train_loader),\r\n",
        "  )\r\n",
        "\r\n",
        "  eval_loss_meter = AverageMeter(name='Loss')\r\n",
        "  eval_acc_meter = AverageMeter(name='Accuracy')\r\n",
        "\r\n",
        "  # Start training\r\n",
        "  eval_global_progress = tqdm(range(0, args.eval_epochs), desc=f'Evaluating')\r\n",
        "  for epoch in eval_global_progress:\r\n",
        "    eval_loss_meter.reset()\r\n",
        "    eval_model.eval()\r\n",
        "    eval_classifier.train()\r\n",
        "    eval_local_progress = tqdm(eval_train_loader, desc=f'Epoch {epoch}/{args.eval_epochs}', disable=True)\r\n",
        "    \r\n",
        "    for idx, (images, labels) in enumerate(eval_local_progress):\r\n",
        "\r\n",
        "      eval_classifier.zero_grad()\r\n",
        "      with torch.no_grad():\r\n",
        "        eval_feature = eval_model(images.to(args.device))\r\n",
        "\r\n",
        "      eval_preds = eval_classifier(eval_feature)\r\n",
        "\r\n",
        "      eval_loss = F.cross_entropy(eval_preds, labels.to(args.device))\r\n",
        "\r\n",
        "      eval_loss.backward()\r\n",
        "      eval_optimizer.step()\r\n",
        "      eval_loss_meter.update(eval_loss.item())\r\n",
        "      eval_lr = eval_lr_scheduler.step()\r\n",
        "      eval_local_progress.set_postfix({'lr':eval_lr, \"loss\":eval_loss_meter.val, 'loss_avg':eval_loss_meter.avg})\r\n",
        "\r\n",
        "  eval_classifier.eval()\r\n",
        "  eval_correct, eval_total = 0, 0\r\n",
        "  eval_acc_meter.reset()\r\n",
        "  for idx, (images, labels) in enumerate(eval_test_loader):\r\n",
        "    with torch.no_grad():\r\n",
        "      eval_feature = eval_model(images.to(args.device))\r\n",
        "      eval_preds = eval_classifier(eval_feature).argmax(dim=1)\r\n",
        "      eval_correct = (eval_preds == labels.to(args.device)).sum().item()\r\n",
        "      eval_acc_meter.update(eval_correct/eval_preds.shape[0])\r\n",
        "  print(f'Accuracy = {eval_acc_meter.avg*100:.2f}')\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QvV0X8xaDri"
      },
      "source": [
        "### liner evaluation ###\r\n",
        "if args.eval:\r\n",
        "  linear_eval(args, byol_ckpt_path)\r\n",
        "  linear_eval(args, siambyol_ckpt_path)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 59,
      "outputs": []
    }
  ]
}