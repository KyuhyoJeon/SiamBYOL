{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SiamBYOL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KyuhyoJeon/SiamBYOL/blob/main/SiamBYOL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U0mliCb7ZTj"
      },
      "source": [
        "# ### Google drive mount ###\r\n",
        "# from google.colab import drive \r\n",
        "# drive.mount('/content/gdrive/')\r\n",
        "# ### ------------------------------------------ ###"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbTSofU9NHbz"
      },
      "source": [
        "### Arguments define ###\r\n",
        "import easydict\r\n",
        "import os\r\n",
        "from datetime import datetime\r\n",
        "\r\n",
        "args = easydict.EasyDict({\r\n",
        "    'image_size':32, # original = 224\r\n",
        "    'learning_rate':0.2, # original lr = 0.2, others = 0.3 or 3e-4\r\n",
        "    'momentum':0, \r\n",
        "    'weight_decay':1.5e-6, \r\n",
        "    'batch_size':4096, \r\n",
        "    'num_epochs':1000, \r\n",
        "    'warmup_epochs':10, \r\n",
        "    'resnet_version':'resnet50', # original = resnet50\r\n",
        "    'optim':'sgd', \r\n",
        "    'checkpoint_epochs':10, \r\n",
        "    # ********************MUST CHECK********************** #\r\n",
        "    'dataset_dir':'./datasets', # dataset directory\r\n",
        "    'ckpt_dir':'/content/gdrive/MyDrive/Colab Notebooks/siambyol/ckpt',   # Network checkpoint directory\r\n",
        "    'num_workers':8, \r\n",
        "    'nodes':1, \r\n",
        "    'gpus':1, \r\n",
        "    'nr':0, \r\n",
        "    'device':'cuda', \r\n",
        "    'eval':True, \r\n",
        "    'eval_epochs':30, \r\n",
        "    # ********************MUST CHECK********************** #\r\n",
        "    'dryrun':True, # check line 47~53\r\n",
        "    'debug':True, # check line 56~62\r\n",
        "    'current_epochs':0, \r\n",
        "    'data_load_check':False\r\n",
        "})\r\n",
        "\r\n",
        "# ********************MUST CHECK********************** #\r\n",
        "# dryrun setting\r\n",
        "if args.dryrun:\r\n",
        "  args.image_size=32\r\n",
        "  args.num_epochs = 100\r\n",
        "  args.batch_size = 256\r\n",
        "  args.num_workers = 4\r\n",
        "  args.resnet_version = 'resnet18'\r\n",
        "\r\n",
        "# ********************MUST CHECK********************** #\r\n",
        "# debug setting\r\n",
        "if args.debug:\r\n",
        "  args.image_size=32\r\n",
        "  args.num_epochs = 1\r\n",
        "  args.batch_size = 2\r\n",
        "  args.num_workers = 0\r\n",
        "  args.debug_subset_size = 8\r\n",
        "  args.resnet_version = 'resnet18'\r\n",
        "  args.eval = False\r\n",
        "  args.data_load_check = True\r\n",
        "  \r\n",
        "\r\n",
        "# make check point directory ex: \"ckpt_dir/resnet18/lars/021805\"\r\n",
        "tmp_dir = os.path.join(args.ckpt_dir, f\"{args.resnet_version}\", f\"{args.optim}\", f\"{datetime.now().strftime('%m%d%H')}\")\r\n",
        "if args.debug:\r\n",
        "  tmp_dir = os.path.join(args.ckpt_dir, f\"{args.resnet_version}\", f\"{args.optim}\", f\"debug\")\r\n",
        "if not os.path.exists(tmp_dir):\r\n",
        "  os.makedirs(tmp_dir)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwAPPgDwNo2j"
      },
      "source": [
        "### Image augmentation define\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "from torchvision import datasets, transforms\r\n",
        "\r\n",
        "class simclr_transform:\r\n",
        "  # augmentations: \r\n",
        "  # random patch, 224 resize, random hrizontal flip, color distortion, \r\n",
        "  # random swquence brightness, contrast, saturation, hue adjustment, \r\n",
        "  # and optional gray scale conversion, Gaussian blur, solarization\r\n",
        "  imagenet_mean_std = [[0.485, 0.456, 0.406],[0.229, 0.224, 0.225]]\r\n",
        "  def __init__(self, size, mean_std=imagenet_mean_std, s=1.0):\r\n",
        "    self.transform = transforms.Compose(\r\n",
        "        [\r\n",
        "        transforms.RandomResizedCrop(size=size), ###\r\n",
        "        transforms.RandomHorizontalFlip(), \r\n",
        "        transforms.RandomApply(\r\n",
        "            [transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)], p=0.8),\r\n",
        "        transforms.RandomGrayscale(p=0.2),\r\n",
        "        transforms.RandomApply(\r\n",
        "            [transforms.GaussianBlur(kernel_size=size//20*2+1, sigma=(0.1, 2.0))], p=0.5), \r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize(*mean_std)\r\n",
        "        ]\r\n",
        "    )\r\n",
        "  def __call__(self, x):\r\n",
        "    x1 = self.transform(x)\r\n",
        "    x2 = self.transform(x)\r\n",
        "    return x1, x2\r\n",
        "\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "class Transform_single():\r\n",
        "  imagenet_mean_std = [[0.485, 0.456, 0.406],[0.229, 0.224, 0.225]]\r\n",
        "  def __init__(self, size, train, normalize=imagenet_mean_std):\r\n",
        "    if train == True:\r\n",
        "      self.transform = transforms.Compose(\r\n",
        "          [\r\n",
        "           transforms.RandomResizedCrop(size, scale=(0.08, 1.0), \r\n",
        "                                        ratio=(3.0/4.0,4.0/3.0), \r\n",
        "                                        interpolation=Image.BICUBIC\r\n",
        "                                        ),\r\n",
        "           transforms.RandomHorizontalFlip(),\r\n",
        "           transforms.ToTensor(),\r\n",
        "           transforms.Normalize(*normalize)\r\n",
        "          ]\r\n",
        "      )\r\n",
        "    else:\r\n",
        "      self.transform = transforms.Compose(\r\n",
        "          [\r\n",
        "           transforms.Resize(int(size*(8/7)), \r\n",
        "                             interpolation=Image.BICUBIC\r\n",
        "                             ), # 224 -> 256 \r\n",
        "           transforms.CenterCrop(size),\r\n",
        "           transforms.ToTensor(),\r\n",
        "           transforms.Normalize(*normalize)\r\n",
        "          ]\r\n",
        "      )\r\n",
        "\r\n",
        "  def __call__(self, x):\r\n",
        "    return self.transform(x)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5jUb9pev062",
        "outputId": "750b3b63-ba5c-414d-eb77-4b3abf6fa56f"
      },
      "source": [
        "### dataset load ###\r\n",
        "cifar_train = datasets.CIFAR10(\r\n",
        "    root=args.dataset_dir, \r\n",
        "    train=True, \r\n",
        "    transform=simclr_transform(args.image_size), \r\n",
        "    download=True\r\n",
        ")\r\n",
        "\r\n",
        "if args.debug:\r\n",
        "  cifar_train = torch.utils.data.Subset(cifar_train, range(0, args.debug_subset_size))\r\n",
        "  cifar_train.classes = cifar_train.dataset.classes\r\n",
        "  cifar_train.targets = cifar_train.dataset.targets\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(\r\n",
        "    cifar_train, \r\n",
        "    batch_size=args.batch_size, \r\n",
        "    shuffle=True, \r\n",
        "    num_workers=args.num_workers, \r\n",
        "    drop_last=True, \r\n",
        "    pin_memory=True\r\n",
        ")\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sSKUET0IL1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "cbe25fb7-0a91-414e-ef7c-4f780555bf85"
      },
      "source": [
        "### dataset load check ###\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def imshow(img):\r\n",
        "  img = img / 2 + 0.5     # unnormalize\r\n",
        "  npimg = img.numpy()\r\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "if args.data_load_check:\r\n",
        "  dataiter = iter(train_loader)\r\n",
        "  (images1, images2), labels = dataiter.next()\r\n",
        "\r\n",
        "  imshow(torchvision.utils.make_grid(images1))\r\n",
        "  imshow(torchvision.utils.make_grid(images2))\r\n",
        "  print(' '.join('%5s' % train_loader.dataset.classes[labels[j]] for j in range(len(labels))))\r\n",
        "  ### ------------------------------------------ ###"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            " frog truck\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2E6ASOUo7PV"
      },
      "source": [
        "### ResNet18 for CIFAR10 define ###\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import os\r\n",
        "# https://raw.githubusercontent.com/huyvnphan/PyTorch_CIFAR10/master/cifar10_models/resnet.py\r\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\r\n",
        "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d']\r\n",
        "\r\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\r\n",
        "  \"\"\"3x3 convolution with padding\"\"\"\r\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\r\n",
        "                    padding=dilation, groups=groups, bias=False, dilation=dilation)\r\n",
        "\r\n",
        "\r\n",
        "def conv1x1(in_planes, out_planes, stride=1):\r\n",
        "  \"\"\"1x1 convolution\"\"\"\r\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\r\n",
        "\r\n",
        "\r\n",
        "class BasicBlock(nn.Module):\r\n",
        "  expansion = 1\r\n",
        "\r\n",
        "  def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\r\n",
        "                base_width=64, dilation=1, norm_layer=None):\r\n",
        "    super(BasicBlock, self).__init__()\r\n",
        "    if norm_layer is None:\r\n",
        "      norm_layer = nn.BatchNorm2d\r\n",
        "    if groups != 1 or base_width != 64:\r\n",
        "      raise ValueError('BasicBlock only supports groups=1 and base_width=64')\r\n",
        "    if dilation > 1:\r\n",
        "      raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\r\n",
        "    # Both self.conv1 and self.downsample layers downsample the input when stride != 1\r\n",
        "    self.conv1 = conv3x3(inplanes, planes, stride)\r\n",
        "    self.bn1 = norm_layer(planes)\r\n",
        "    self.relu = nn.ReLU(inplace=True)\r\n",
        "    self.conv2 = conv3x3(planes, planes)\r\n",
        "    self.bn2 = norm_layer(planes)\r\n",
        "    self.downsample = downsample\r\n",
        "    self.stride = stride\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    identity = x\r\n",
        "\r\n",
        "    out = self.conv1(x)\r\n",
        "    out = self.bn1(out)\r\n",
        "    out = self.relu(out)\r\n",
        "\r\n",
        "    out = self.conv2(out)\r\n",
        "    out = self.bn2(out)\r\n",
        "\r\n",
        "    if self.downsample is not None:\r\n",
        "        identity = self.downsample(x)\r\n",
        "\r\n",
        "    out += identity\r\n",
        "    out = self.relu(out)\r\n",
        "\r\n",
        "    return out\r\n",
        "\r\n",
        "\r\n",
        "class Bottleneck(nn.Module):\r\n",
        "  expansion = 4\r\n",
        "\r\n",
        "  def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\r\n",
        "                base_width=64, dilation=1, norm_layer=None):\r\n",
        "    super(Bottleneck, self).__init__()\r\n",
        "    if norm_layer is None:\r\n",
        "        norm_layer = nn.BatchNorm2d\r\n",
        "    width = int(planes * (base_width / 64.)) * groups\r\n",
        "    # Both self.conv2 and self.downsample layers downsample the input when stride != 1\r\n",
        "    self.conv1 = conv1x1(inplanes, width)\r\n",
        "    self.bn1 = norm_layer(width)\r\n",
        "    self.conv2 = conv3x3(width, width, stride, groups, dilation)\r\n",
        "    self.bn2 = norm_layer(width)\r\n",
        "    self.conv3 = conv1x1(width, planes * self.expansion)\r\n",
        "    self.bn3 = norm_layer(planes * self.expansion)\r\n",
        "    self.relu = nn.ReLU(inplace=True)\r\n",
        "    self.downsample = downsample\r\n",
        "    self.stride = stride\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "      identity = x\r\n",
        "\r\n",
        "      out = self.conv1(x)\r\n",
        "      out = self.bn1(out)\r\n",
        "      out = self.relu(out)\r\n",
        "\r\n",
        "      out = self.conv2(out)\r\n",
        "      out = self.bn2(out)\r\n",
        "      out = self.relu(out)\r\n",
        "\r\n",
        "      out = self.conv3(out)\r\n",
        "      out = self.bn3(out)\r\n",
        "\r\n",
        "      if self.downsample is not None:\r\n",
        "          identity = self.downsample(x)\r\n",
        "\r\n",
        "      out += identity\r\n",
        "      out = self.relu(out)\r\n",
        "\r\n",
        "      return out\r\n",
        "\r\n",
        "\r\n",
        "class ResNet(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, block, layers, num_classes=10, zero_init_residual=False,\r\n",
        "                groups=1, width_per_group=64, replace_stride_with_dilation=None,\r\n",
        "                norm_layer=None):\r\n",
        "    super(ResNet, self).__init__()\r\n",
        "    if norm_layer is None:\r\n",
        "      norm_layer = nn.BatchNorm2d\r\n",
        "    self._norm_layer = norm_layer\r\n",
        "\r\n",
        "    self.inplanes = 64\r\n",
        "    self.dilation = 1\r\n",
        "    if replace_stride_with_dilation is None:\r\n",
        "      # each element in the tuple indicates if we should replace\r\n",
        "      # the 2x2 stride with a dilated convolution instead\r\n",
        "      replace_stride_with_dilation = [False, False, False]\r\n",
        "    if len(replace_stride_with_dilation) != 3:\r\n",
        "      raise ValueError(\"replace_stride_with_dilation should be None \"\r\n",
        "                        \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\r\n",
        "    self.groups = groups\r\n",
        "    self.base_width = width_per_group\r\n",
        "    \r\n",
        "    ## CIFAR10: kernel_size 7 -> 3, stride 2 -> 1, padding 3->1\r\n",
        "    self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\r\n",
        "    ## END\r\n",
        "    \r\n",
        "    self.bn1 = norm_layer(self.inplanes)\r\n",
        "    self.relu = nn.ReLU(inplace=True)\r\n",
        "    # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
        "    self.layer1 = self._make_layer(block, 64, layers[0])\r\n",
        "    self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\r\n",
        "                                    dilate=replace_stride_with_dilation[0])\r\n",
        "    self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\r\n",
        "                                    dilate=replace_stride_with_dilation[1])\r\n",
        "    self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\r\n",
        "                                    dilate=replace_stride_with_dilation[2])\r\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\r\n",
        "    self.fc = nn.Linear(512 * block.expansion, num_classes)\r\n",
        "\r\n",
        "    for m in self.modules():\r\n",
        "      if isinstance(m, nn.Conv2d):\r\n",
        "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n",
        "      elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\r\n",
        "        nn.init.constant_(m.weight, 1)\r\n",
        "        nn.init.constant_(m.bias, 0)\r\n",
        "\r\n",
        "    # Zero-initialize the last BN in each residual branch,\r\n",
        "    # so that the residual branch starts with zeros, and each residual block behaves like an identity.\r\n",
        "    # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\r\n",
        "    if zero_init_residual:\r\n",
        "      for m in self.modules():\r\n",
        "        if isinstance(m, Bottleneck):\r\n",
        "          nn.init.constant_(m.bn3.weight, 0)\r\n",
        "        elif isinstance(m, BasicBlock):\r\n",
        "          nn.init.constant_(m.bn2.weight, 0)\r\n",
        "\r\n",
        "  def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\r\n",
        "    norm_layer = self._norm_layer\r\n",
        "    downsample = None\r\n",
        "    previous_dilation = self.dilation\r\n",
        "    if dilate:\r\n",
        "        self.dilation *= stride\r\n",
        "        stride = 1\r\n",
        "    if stride != 1 or self.inplanes != planes * block.expansion:\r\n",
        "        downsample = nn.Sequential(\r\n",
        "            conv1x1(self.inplanes, planes * block.expansion, stride),\r\n",
        "            norm_layer(planes * block.expansion),\r\n",
        "        )\r\n",
        "\r\n",
        "    layers = []\r\n",
        "    layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\r\n",
        "                        self.base_width, previous_dilation, norm_layer))\r\n",
        "    self.inplanes = planes * block.expansion\r\n",
        "    for _ in range(1, blocks):\r\n",
        "        layers.append(block(self.inplanes, planes, groups=self.groups,\r\n",
        "                            base_width=self.base_width, dilation=self.dilation,\r\n",
        "                            norm_layer=norm_layer))\r\n",
        "\r\n",
        "    return nn.Sequential(*layers)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.conv1(x)\r\n",
        "    x = self.bn1(x)\r\n",
        "    x = self.relu(x)\r\n",
        "    # x = self.maxpool(x)\r\n",
        "\r\n",
        "    x = self.layer1(x)\r\n",
        "    x = self.layer2(x)\r\n",
        "    x = self.layer3(x)\r\n",
        "    x = self.layer4(x)\r\n",
        "\r\n",
        "    x = self.avgpool(x)\r\n",
        "    x = x.reshape(x.size(0), -1)\r\n",
        "    x = self.fc(x)\r\n",
        "\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "def _resnet(arch, block, layers, pretrained, progress, device, **kwargs):\r\n",
        "  model = ResNet(block, layers, **kwargs)\r\n",
        "  if pretrained:\r\n",
        "      script_dir = os.path.dirname(__file__)\r\n",
        "      state_dict = torch.load(script_dir + '/state_dicts/'+arch+'.pt', map_location=device)\r\n",
        "      model.load_state_dict(state_dict)\r\n",
        "  return model\r\n",
        "\r\n",
        "\r\n",
        "def resnet18(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNet-18 model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress, device,\r\n",
        "                  **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnet34(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNet-34 model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress, device,\r\n",
        "                  **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnet50(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNet-50 model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress, device,\r\n",
        "                  **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnet101(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNet-101 model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress, device,\r\n",
        "                  **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnet152(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNet-152 model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress, device,\r\n",
        "                  **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnext50_32x4d(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNeXt-50 32x4d model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  kwargs['groups'] = 32\r\n",
        "  kwargs['width_per_group'] = 4\r\n",
        "  return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3],\r\n",
        "                  pretrained, progress, device, **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnext101_32x8d(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNeXt-101 32x8d model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  kwargs['groups'] = 32\r\n",
        "  kwargs['width_per_group'] = 8\r\n",
        "  return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\r\n",
        "                  pretrained, progress, device, **kwargs)\r\n",
        "\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh_OjbkTKGV-"
      },
      "source": [
        "### resnet call ###\r\n",
        "import copy\r\n",
        "import torch.nn as nn\r\n",
        "from torchvision import models\r\n",
        "\r\n",
        "if args.resnet_version is not None:\r\n",
        "  resnet = eval(f'{args.resnet_version}()')\r\n",
        "  siamresnet = copy.deepcopy(resnet)\r\n",
        "  \r\n",
        "  resnet.output_dim = resnet.fc.in_features\r\n",
        "  resnet.fc = nn.Identity()\r\n",
        "  siamresnet.output_dim = siamresnet.fc.in_features\r\n",
        "  siamresnet.fc = nn.Identity()\r\n",
        "else:\r\n",
        "  raise NotImplementedError(\"Backbone is not implemented!\")\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDkTLBPcy1lv"
      },
      "source": [
        "### siambyol network define ###\r\n",
        "import math\r\n",
        "from torch.nn import functional\r\n",
        "\r\n",
        "hidden_size=4096\r\n",
        "projection_size=256\r\n",
        "\r\n",
        "class MLP(nn.Module):\r\n",
        "  def __init__(self, input_dim):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.net = nn.Sequential(\r\n",
        "        nn.Linear(input_dim, hidden_size), \r\n",
        "        nn.BatchNorm1d(hidden_size, momentum=1-0.9, eps=1e-5), \r\n",
        "        nn.ReLU(inplace=True), \r\n",
        "        nn.Linear(hidden_size, projection_size)\r\n",
        "    )\r\n",
        "  def forward(self, x):\r\n",
        "    return self.net(x)\r\n",
        "\r\n",
        "class BYOL(nn.Module):\r\n",
        "  def __init__(self, backbone):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.backbone=backbone\r\n",
        "    self.projector = MLP(backbone.output_dim)\r\n",
        "    self.online_encoder = nn.Sequential(\r\n",
        "        self.backbone, \r\n",
        "        self.projector,\r\n",
        "    )\r\n",
        "    self.predictor = MLP(projection_size)\r\n",
        "    self.target_encoder = copy.deepcopy(self.online_encoder)\r\n",
        "\r\n",
        "  def set_online(self, model):\r\n",
        "    del self.online_encoder\r\n",
        "    self.online_encoder = copy.deepcopy(model)\r\n",
        "\r\n",
        "  def target_ema(self, k, K, base_tau=0.996):\r\n",
        "    return 1-(1-base_tau)*(math.cos(math.pi*k/K)+1)/2\r\n",
        "\r\n",
        "  def update_moving_average(self, global_step, max_steps):\r\n",
        "    tau = self.target_ema(global_step, max_steps)\r\n",
        "    for online, target in zip(self.online_encoder.parameters(), self.target_encoder.parameters()):\r\n",
        "      target.data = tau*target.data + (1-tau)*online.data\r\n",
        "  \r\n",
        "  def loss_function(self, p, z):\r\n",
        "    p=functional.normalize(p, dim=-1, p=2)\r\n",
        "    z=functional.normalize(z, dim=-1, p=2)\r\n",
        "    return 2 - 2*(p*z).sum(dim=-1)\r\n",
        "\r\n",
        "  def forward(self, x1, x2):\r\n",
        "    z1_online, z2_online = self.online_encoder(x1), self.online_encoder(x2)\r\n",
        "    p1_online, p2_online = self.predictor(z1_online), self.predictor(z2_online)\r\n",
        "    with torch.no_grad():\r\n",
        "      z1_target, z2_target = self.target_encoder(x1), self.target_encoder(x2)\r\n",
        "    \r\n",
        "    loss1, loss2 = self.loss_function(p1_online, z2_target.detach()), self.loss_function(p2_online, z1_target.detach())\r\n",
        "\r\n",
        "    loss = loss1+loss2\r\n",
        "    return loss.mean()\r\n",
        "\r\n",
        "class SiamBYOL(nn.Module):\r\n",
        "  def __init__(self, backbone):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.backbone=backbone\r\n",
        "    self.projector = MLP(backbone.output_dim)\r\n",
        "    self.online_encoder = nn.Sequential(\r\n",
        "        self.backbone, \r\n",
        "        self.projector,\r\n",
        "    )\r\n",
        "    self.predictor = MLP(projection_size)\r\n",
        "    self.target_encoder = None\r\n",
        "  \r\n",
        "  def set_target(self, model):\r\n",
        "    del self.target_encoder\r\n",
        "    self.target_encoder = copy.deepcopy(model)\r\n",
        "  \r\n",
        "  def loss_function(self, p, z):\r\n",
        "    p=functional.normalize(p, dim=-1, p=2)\r\n",
        "    z=functional.normalize(z, dim=-1, p=2)\r\n",
        "    return 2 - 2*(p*z).sum(dim=-1)\r\n",
        "\r\n",
        "  def target_ema(self, k, K, base_tau=0.996):\r\n",
        "    return 1-(1-base_tau)*(math.cos(math.pi*k/K)+1)/2\r\n",
        "\r\n",
        "  def update_moving_average(self, global_step, max_steps):\r\n",
        "    tau = self.target_ema(global_step, max_steps)\r\n",
        "    for online, target in zip(self.online_encoder.parameters(), self.target_encoder.parameters()):\r\n",
        "      target.data = tau*target.data + (1-tau)*online.data\r\n",
        "\r\n",
        "  def forward(self, x1, x2, target):\r\n",
        "    z1_online, z2_online = self.online_encoder(x1), self.online_encoder(x2)\r\n",
        "    p1_online, p2_online = self.predictor(z1_online), self.predictor(z2_online)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      self.set_target(target)\r\n",
        "      z1_target, z2_target = self.target_encoder(x1), self.target_encoder(x2)\r\n",
        "    \r\n",
        "    loss1, loss2 = self.loss_function(p1_online, z2_target.detach()), self.loss_function(p2_online, z1_target.detach())\r\n",
        "\r\n",
        "    loss = loss1+loss2\r\n",
        "    return loss.mean()\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoNT2XuVRa_t"
      },
      "source": [
        "### byol network call ###\r\n",
        "byol = BYOL(resnet)\r\n",
        "\r\n",
        "# model load, check 'pre model path' to load pre model\r\n",
        "if args.current_epochs != 0:\r\n",
        "  pre_model = torch.load('')\r\n",
        "  msg = byol.load_state_dict(pre_model['state_dict'])\r\n",
        "  print(msg)\r\n",
        "\r\n",
        "byol = byol.to(args.device)\r\n",
        "byol = torch.nn.DataParallel(byol)\r\n",
        "\r\n",
        "siambyol = SiamBYOL(siamresnet)\r\n",
        "\r\n",
        "# model load, check 'pre model path' to load pre model\r\n",
        "if args.current_epochs != 0:\r\n",
        "  pre_model = torch.load('')\r\n",
        "  msg = siambyol.load_state_dict(pre_model['state_dict'])\r\n",
        "  print(msg)\r\n",
        "\r\n",
        "siambyol = siambyol.to(args.device)\r\n",
        "siambyol = torch.nn.DataParallel(siambyol)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VonOn4aaUCV2"
      },
      "source": [
        "### optimizer call ###\r\n",
        "from torch.optim import SGD\r\n",
        "\r\n",
        "predictor_prefix = ('module.predictor', 'predictor')\r\n",
        "byol_parameters = [{\r\n",
        "    'name': 'base',\r\n",
        "    'params': [param for name, param in byol.named_parameters() if not name.startswith(predictor_prefix)],\r\n",
        "    'lr': args.learning_rate\r\n",
        "},{\r\n",
        "    'name': 'predictor',\r\n",
        "    'params': [param for name, param in byol.named_parameters() if name.startswith(predictor_prefix)],\r\n",
        "    'lr': args.learning_rate\r\n",
        "}]\r\n",
        "siambyol_parameters = [{\r\n",
        "    'name': 'base',\r\n",
        "    'params': [param for name, param in siambyol.named_parameters() if not name.startswith(predictor_prefix)],\r\n",
        "    'lr': args.learning_rate\r\n",
        "},{\r\n",
        "    'name': 'predictor',\r\n",
        "    'params': [param for name, param in siambyol.named_parameters() if name.startswith(predictor_prefix)],\r\n",
        "    'lr': args.learning_rate\r\n",
        "}]\r\n",
        "\r\n",
        "byol_optimizer = SGD(byol_parameters, lr=args.learning_rate*args.batch_size/256, momentum=0.9)\r\n",
        "siambyol_optimizer = SGD(siambyol_parameters, lr=args.learning_rate*args.batch_size/256, momentum=0.9)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dELIoWzCuZt4"
      },
      "source": [
        "### learning rate scheduler define ###\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "class LR_Scheduler(object):\r\n",
        "  def __init__(self, optimizer, warmup_epochs, warmup_lr, num_epochs, base_lr, final_lr, iter_per_epoch, constant_predictor_lr=False):\r\n",
        "    self.base_lr = base_lr\r\n",
        "    self.constant_predictor_lr = constant_predictor_lr\r\n",
        "    warmup_iter = iter_per_epoch * warmup_epochs\r\n",
        "    warmup_lr_schedule = np.linspace(warmup_lr, base_lr, warmup_iter)\r\n",
        "    decay_iter = iter_per_epoch * (num_epochs - warmup_epochs)\r\n",
        "    cosine_lr_schedule = final_lr+0.5*(base_lr-final_lr)*(1+np.cos(np.pi*np.arange(decay_iter)/decay_iter))\r\n",
        "    \r\n",
        "    self.lr_schedule = np.concatenate((warmup_lr_schedule, cosine_lr_schedule))\r\n",
        "    self.optimizer = optimizer\r\n",
        "    self.iter = 0\r\n",
        "    self.current_lr = 0\r\n",
        "  def step(self):\r\n",
        "    for param_group in self.optimizer.param_groups:\r\n",
        "\r\n",
        "      if self.constant_predictor_lr and param_group['name'] == 'predictor':\r\n",
        "        param_group['lr'] = self.base_lr\r\n",
        "      else:\r\n",
        "        lr = param_group['lr'] = self.lr_schedule[self.iter]\r\n",
        "    \r\n",
        "    self.iter += 1\r\n",
        "    self.current_lr = lr\r\n",
        "    return lr\r\n",
        "  def get_lr(self):\r\n",
        "    return self.current_lr\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHd0qVZ_JYW9"
      },
      "source": [
        "### lr_scheduler define ###\r\n",
        "byol_lr_scheduler = LR_Scheduler(byol_optimizer, args.warmup_epochs, 0, args.num_epochs, args.learning_rate*args.batch_size/256, 0, len(train_loader), constant_predictor_lr=True)\r\n",
        "siambyol_lr_scheduler = LR_Scheduler(siambyol_optimizer, args.warmup_epochs, 0, args.num_epochs, args.learning_rate*args.batch_size/256, 0, len(train_loader), constant_predictor_lr=True)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur2YMpd2Vi-U",
        "outputId": "614e4c71-4059-4f0e-aaa3-86715eaff914"
      },
      "source": [
        "### Training ###\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "from collections import defaultdict\r\n",
        "from datetime import datetime\r\n",
        "from tqdm import tqdm\r\n",
        "import os\r\n",
        "\r\n",
        "writer = SummaryWriter()\r\n",
        "\r\n",
        "global_step = 0\r\n",
        "for epoch in tqdm(range(args.current_epochs, args.num_epochs), desc=f'Training'):\r\n",
        "  metrics = defaultdict(list)\r\n",
        "  \r\n",
        "  for step, ((x1, x2), labels) in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{args.num_epochs}')):\r\n",
        "    x1, x2 = x1.cuda(non_blocking=True), x2.cuda(non_blocking=True)\r\n",
        "\r\n",
        "    byol_loss = byol(x1, x2)\r\n",
        "    byol_optimizer.zero_grad()\r\n",
        "    byol_loss.backward()\r\n",
        "    byol_optimizer.step()\r\n",
        "    byol_lr_scheduler.step() # defined scheduler\r\n",
        "    byol.module.update_moving_average(step+1, len(train_loader))\r\n",
        "\r\n",
        "    siambyol_loss = siambyol(x1, x2, byol.module.online_encoder)\r\n",
        "    siambyol_optimizer.zero_grad()\r\n",
        "    siambyol_loss.backward()\r\n",
        "    siambyol_optimizer.step()\r\n",
        "    siambyol_lr_scheduler.step()\r\n",
        "    siambyol.module.update_moving_average(step+1, len(train_loader))\r\n",
        "\r\n",
        "    byol.module.set_online(siambyol.module.target_encoder)\r\n",
        "    \r\n",
        "    writer.add_scalar(\"Loss/train_step\", siambyol_loss, global_step)\r\n",
        "    metrics[\"Loss/train\"].append(siambyol_loss.item())\r\n",
        "    global_step += 1\r\n",
        "  \r\n",
        "  for k, v in metrics.items():\r\n",
        "    writer.add_scalar(k, np.array(v).mean(), epoch+1)\r\n",
        "\r\n",
        "  if (epoch+1)%args.checkpoint_epochs == 0:\r\n",
        "    byol_ckpt_path = os.path.join(tmp_dir, f\"byol_{args.optim}_{epoch+1}.pt\")\r\n",
        "    print(f'Saving model at epoch {epoch+1}')\r\n",
        "    torch.save({\r\n",
        "        'epoch':epoch+1, \r\n",
        "        'state_dict':byol.module.state_dict()\r\n",
        "    }, byol_ckpt_path)\r\n",
        "    siambyol_ckpt_path = os.path.join(tmp_dir, f\"siambyol_{args.optim}_{epoch+1}.pt\")\r\n",
        "    print(f'Saving model at epoch {epoch+1}')\r\n",
        "    torch.save({\r\n",
        "        'epoch':epoch+1, \r\n",
        "        'state_dict':siambyol.module.state_dict()\r\n",
        "    }, siambyol_ckpt_path)\r\n",
        "\r\n",
        "byol_ckpt_path = os.path.join(tmp_dir, f\"byol_{args.optim}_final.pt\")\r\n",
        "print(f'Saving final model at epoch {epoch+1}')\r\n",
        "torch.save({\r\n",
        "    'epoch':epoch+1, \r\n",
        "    'state_dict':byol.module.state_dict()\r\n",
        "}, byol_ckpt_path)\r\n",
        "siambyol_ckpt_path = os.path.join(tmp_dir, f\"siambyol_{args.optim}_final.pt\")\r\n",
        "print(f'Saving final model at epoch {epoch+1}')\r\n",
        "torch.save({\r\n",
        "    'epoch':epoch+1, \r\n",
        "    'state_dict':siambyol.module.state_dict()\r\n",
        "}, siambyol_ckpt_path)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 1/1:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1/1:  25%|██▌       | 1/4 [00:00<00:00,  7.04it/s]\u001b[A\n",
            "Epoch 1/1:  50%|█████     | 2/4 [00:00<00:00,  6.92it/s]\u001b[A\n",
            "Epoch 1/1:  75%|███████▌  | 3/4 [00:00<00:00,  6.88it/s]\u001b[A\n",
            "Epoch 1/1: 100%|██████████| 4/4 [00:00<00:00,  6.72it/s]\n",
            "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving final model at epoch 1\n",
            "Saving final model at epoch 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRogCvo2Wu_2"
      },
      "source": [
        "### Linear Evaluation define ###\r\n",
        "import torch.nn.functional as F \r\n",
        "\r\n",
        "class AverageMeter():\r\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\r\n",
        "    def __init__(self, name, fmt=':f'):\r\n",
        "        self.name = name\r\n",
        "        self.fmt = fmt\r\n",
        "        self.log = []\r\n",
        "        self.val = 0\r\n",
        "        self.avg = 0\r\n",
        "        self.sum = 0\r\n",
        "        self.count = 0\r\n",
        "\r\n",
        "    def reset(self):\r\n",
        "        self.log.append(self.avg)\r\n",
        "        self.val = 0\r\n",
        "        self.avg = 0\r\n",
        "        self.sum = 0\r\n",
        "        self.count = 0\r\n",
        "\r\n",
        "    def update(self, val, n=1):\r\n",
        "        self.val = val\r\n",
        "        self.sum += val * n\r\n",
        "        self.count += n\r\n",
        "        self.avg = self.sum / self.count\r\n",
        "\r\n",
        "    def __str__(self):\r\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\r\n",
        "        return fmtstr.format(**self.__dict__)\r\n",
        "\r\n",
        "def linear_eval(args, eval_from):\r\n",
        "  eval_train_loader = torch.utils.data.DataLoader(\r\n",
        "      torchvision.datasets.CIFAR10(\r\n",
        "          root=args.dataset_dir, \r\n",
        "          train=True, \r\n",
        "          download=False, \r\n",
        "          transform=Transform_single(size=args.image_size, train=True), \r\n",
        "      ), \r\n",
        "      shuffle=True,\r\n",
        "      batch_size=args.batch_size,\r\n",
        "      num_workers=args.num_workers,\r\n",
        "      drop_last=True,\r\n",
        "      pin_memory=True,\r\n",
        "  )\r\n",
        "\r\n",
        "  eval_test_loader = torch.utils.data.DataLoader(\r\n",
        "      torchvision.datasets.CIFAR10(\r\n",
        "          root=args.dataset_dir, \r\n",
        "          train=False, \r\n",
        "          download=False, \r\n",
        "          transform=Transform_single(size=args.image_size, train=False), \r\n",
        "      ), \r\n",
        "      shuffle=False,\r\n",
        "      batch_size=args.batch_size,\r\n",
        "      num_workers=args.num_workers,\r\n",
        "      drop_last=True,\r\n",
        "      pin_memory=True,\r\n",
        "  )\r\n",
        "\r\n",
        "  eval_model = eval(f\"{args.resnet_version}()\")\r\n",
        "  # eval_model = eval(f\"model.{args.resnet_version}()\")\r\n",
        "  eval_model.output_dim = eval_model.fc.in_features\r\n",
        "  eval_model.fc = torch.nn.Identity()\r\n",
        "  eval_classifier = nn.Linear(in_features=eval_model.output_dim, out_features=10, bias=True).to(args.device)\r\n",
        "\r\n",
        "  ###\r\n",
        "  assert eval_from is not None\r\n",
        "  eval_save_dict = torch.load(eval_from, map_location='cuda')\r\n",
        "  eval_msg = eval_model.load_state_dict({k[9:]:v for k, v in eval_save_dict['state_dict'].items() if k.startswith('backbone.')}, strict=True)\r\n",
        "  \r\n",
        "  print(eval_msg)\r\n",
        "  eval_model = eval_model.to(args.device)\r\n",
        "  eval_model = torch.nn.DataParallel(eval_model)\r\n",
        "\r\n",
        "  # if torch.cuda.device_count() > 1: eval_classifier = torch.nn.SyncBatchNorm.convert_sync_batchnorm(eval_classifier)\r\n",
        "  eval_classifier = torch.nn.DataParallel(eval_classifier)\r\n",
        "  # define optimizer 'sgd', eval_classifier, lr=eval_base_lr=30, momentum=eval_optim_momentum-0.9, weight_decay=eval_optim_weight_decay=0\r\n",
        "  predictor_prefix = ('module.predictor', 'predictor')\r\n",
        "  parameters = [{\r\n",
        "      'name': 'base',\r\n",
        "      'params': [param for name, param in eval_classifier.named_parameters() if not name.startswith(predictor_prefix)],\r\n",
        "      'lr': 30\r\n",
        "  },{\r\n",
        "      'name': 'predictor',\r\n",
        "      'params': [param for name, param in eval_classifier.named_parameters() if name.startswith(predictor_prefix)],\r\n",
        "      'lr': 30\r\n",
        "  }]\r\n",
        "  eval_optimizer = torch.optim.SGD(parameters, lr=30, momentum=0.9, weight_decay=0)\r\n",
        "\r\n",
        "  # define lr scheduler\r\n",
        "  eval_lr_scheduler = LR_Scheduler(\r\n",
        "      eval_optimizer,\r\n",
        "      0, 0*args.batch_size/256, \r\n",
        "      30, 30*args.batch_size/256, 0*args.batch_size/256, \r\n",
        "      len(eval_train_loader),\r\n",
        "  )\r\n",
        "\r\n",
        "  eval_loss_meter = AverageMeter(name='Loss')\r\n",
        "  eval_acc_meter = AverageMeter(name='Accuracy')\r\n",
        "\r\n",
        "  # Start training\r\n",
        "  eval_global_progress = tqdm(range(0, args.eval_epochs), desc=f'Evaluating')\r\n",
        "  for epoch in eval_global_progress:\r\n",
        "    eval_loss_meter.reset()\r\n",
        "    eval_model.eval()\r\n",
        "    eval_classifier.train()\r\n",
        "    eval_local_progress = tqdm(eval_train_loader, desc=f'Epoch {epoch}/{args.eval_epochs}', disable=True)\r\n",
        "    \r\n",
        "    for idx, (images, labels) in enumerate(eval_local_progress):\r\n",
        "\r\n",
        "      eval_classifier.zero_grad()\r\n",
        "      with torch.no_grad():\r\n",
        "        eval_feature = eval_model(images.to(args.device))\r\n",
        "\r\n",
        "      eval_preds = eval_classifier(eval_feature)\r\n",
        "\r\n",
        "      eval_loss = F.cross_entropy(eval_preds, labels.to(args.device))\r\n",
        "\r\n",
        "      eval_loss.backward()\r\n",
        "      eval_optimizer.step()\r\n",
        "      eval_loss_meter.update(eval_loss.item())\r\n",
        "      eval_lr = eval_lr_scheduler.step()\r\n",
        "      eval_local_progress.set_postfix({'lr':eval_lr, \"loss\":eval_loss_meter.val, 'loss_avg':eval_loss_meter.avg})\r\n",
        "\r\n",
        "  eval_classifier.eval()\r\n",
        "  eval_correct, eval_total = 0, 0\r\n",
        "  eval_acc_meter.reset()\r\n",
        "  for idx, (images, labels) in enumerate(eval_test_loader):\r\n",
        "    with torch.no_grad():\r\n",
        "      eval_feature = eval_model(images.to(args.device))\r\n",
        "      eval_preds = eval_classifier(eval_feature).argmax(dim=1)\r\n",
        "      eval_correct = (eval_preds == labels.to(args.device)).sum().item()\r\n",
        "      eval_acc_meter.update(eval_correct/eval_preds.shape[0])\r\n",
        "  print(f'Accuracy = {eval_acc_meter.avg*100:.2f}')\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QvV0X8xaDri"
      },
      "source": [
        "### liner evaluation ###\r\n",
        "if args.eval:\r\n",
        "  linear_eval(args, byol_ckpt_path)\r\n",
        "  linear_eval(args, siambyol_ckpt_path)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 74,
      "outputs": []
    }
  ]
}