{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SiamBYOL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KyuhyoJeon/SiamBYOL/blob/main/SiamBYOL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U0mliCb7ZTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eded37d4-4d7f-4f52-a27b-b5822a909d4b"
      },
      "source": [
        "# ### Google drive mount ###\r\n",
        "# from google.colab import drive \r\n",
        "# drive.mount('/content/gdrive/')\r\n",
        "# ### ------------------------------------------ ###"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbTSofU9NHbz"
      },
      "source": [
        "### Arguments define ###\r\n",
        "import easydict\r\n",
        "import os\r\n",
        "from datetime import datetime\r\n",
        "\r\n",
        "args = easydict.EasyDict({\r\n",
        "    'image_size':32, # original = 224\r\n",
        "    'learning_rate':0.2, # original lr = 0.2, others = 0.3 or 3e-4\r\n",
        "    'momentum':0, \r\n",
        "    'weight_decay':1.5e-6, \r\n",
        "    'batch_size':4096, \r\n",
        "    'num_epochs':1000, \r\n",
        "    'warmup_epochs':10, \r\n",
        "    'resnet_version':'resnet50', # original = resnet50\r\n",
        "    'optim':'sgd', \r\n",
        "    'checkpoint_epochs':10, \r\n",
        "    # ********************MUST CHECK********************** #\r\n",
        "    'dataset_dir':'./datasets', # dataset directory\r\n",
        "    'ckpt_dir':'/content/gdrive/MyDrive/Colab Notebooks/siambyol/ckpt',   # Network checkpoint directory\r\n",
        "    'num_workers':8, \r\n",
        "    'nodes':1, \r\n",
        "    'gpus':1, \r\n",
        "    'nr':0, \r\n",
        "    'device':'cuda', \r\n",
        "    'eval':True, \r\n",
        "    'eval_epochs':30, \r\n",
        "    # ********************MUST CHECK********************** #\r\n",
        "    'dryrun':True, # check line 47~53\r\n",
        "    'debug':True, # check line 56~62\r\n",
        "    'current_epochs':0, \r\n",
        "    'data_load_check':False\r\n",
        "})\r\n",
        "\r\n",
        "# ********************MUST CHECK********************** #\r\n",
        "# dryrun setting\r\n",
        "if args.dryrun:\r\n",
        "  args.image_size=32\r\n",
        "  args.num_epochs = 100\r\n",
        "  args.batch_size = 256\r\n",
        "  args.num_workers = 4\r\n",
        "  args.resnet_version = 'resnet18'\r\n",
        "\r\n",
        "# ********************MUST CHECK********************** #\r\n",
        "# debug setting\r\n",
        "if args.debug:\r\n",
        "  args.image_size=32\r\n",
        "  args.num_epochs = 1\r\n",
        "  args.batch_size = 2\r\n",
        "  args.num_workers = 0\r\n",
        "  args.debug_subset_size = 8\r\n",
        "  args.resnet_version = 'resnet18'\r\n",
        "  args.eval = False\r\n",
        "  args.data_load_check = True\r\n",
        "  \r\n",
        "\r\n",
        "# make check point directory ex: \"ckpt_dir/resnet18/lars/021805\"\r\n",
        "tmp_dir = os.path.join(args.ckpt_dir, f\"{args.resnet_version}\", f\"{args.optim}\", f\"{datetime.now().strftime('%m%d%H')}\")\r\n",
        "if args.debug:\r\n",
        "  tmp_dir = os.path.join(args.ckpt_dir, f\"{args.resnet_version}\", f\"{args.optim}\", f\"debug\")\r\n",
        "if not os.path.exists(tmp_dir):\r\n",
        "  os.makedirs(tmp_dir)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwAPPgDwNo2j"
      },
      "source": [
        "### Image augmentation define\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "from torchvision import datasets, transforms\r\n",
        "\r\n",
        "class simclr_transform:\r\n",
        "  # augmentations: \r\n",
        "  # random patch, 224 resize, random hrizontal flip, color distortion, \r\n",
        "  # random swquence brightness, contrast, saturation, hue adjustment, \r\n",
        "  # and optional gray scale conversion, Gaussian blur, solarization\r\n",
        "  imagenet_mean_std = [[0.485, 0.456, 0.406],[0.229, 0.224, 0.225]]\r\n",
        "  def __init__(self, size, mean_std=imagenet_mean_std, s=1.0):\r\n",
        "    self.transform = transforms.Compose(\r\n",
        "        [\r\n",
        "        transforms.RandomResizedCrop(size=size), ###\r\n",
        "        transforms.RandomHorizontalFlip(), \r\n",
        "        transforms.RandomApply(\r\n",
        "            [transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)], p=0.8),\r\n",
        "        transforms.RandomGrayscale(p=0.2),\r\n",
        "        transforms.RandomApply(\r\n",
        "            [transforms.GaussianBlur(kernel_size=size//20*2+1, sigma=(0.1, 2.0))], p=0.5), \r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize(*mean_std)\r\n",
        "        ]\r\n",
        "    )\r\n",
        "  def __call__(self, x):\r\n",
        "    x1 = self.transform(x)\r\n",
        "    x2 = self.transform(x)\r\n",
        "    return x1, x2\r\n",
        "\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "class Transform_single():\r\n",
        "  imagenet_mean_std = [[0.485, 0.456, 0.406],[0.229, 0.224, 0.225]]\r\n",
        "  def __init__(self, size, train, normalize=imagenet_mean_std):\r\n",
        "    if train == True:\r\n",
        "      self.transform = transforms.Compose(\r\n",
        "          [\r\n",
        "           transforms.RandomResizedCrop(size, scale=(0.08, 1.0), \r\n",
        "                                        ratio=(3.0/4.0,4.0/3.0), \r\n",
        "                                        interpolation=Image.BICUBIC\r\n",
        "                                        ),\r\n",
        "           transforms.RandomHorizontalFlip(),\r\n",
        "           transforms.ToTensor(),\r\n",
        "           transforms.Normalize(*normalize)\r\n",
        "          ]\r\n",
        "      )\r\n",
        "    else:\r\n",
        "      self.transform = transforms.Compose(\r\n",
        "          [\r\n",
        "           transforms.Resize(int(size*(8/7)), \r\n",
        "                             interpolation=Image.BICUBIC\r\n",
        "                             ), # 224 -> 256 \r\n",
        "           transforms.CenterCrop(size),\r\n",
        "           transforms.ToTensor(),\r\n",
        "           transforms.Normalize(*normalize)\r\n",
        "          ]\r\n",
        "      )\r\n",
        "\r\n",
        "  def __call__(self, x):\r\n",
        "    return self.transform(x)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5jUb9pev062",
        "outputId": "8277e54e-64c4-4017-fd01-5775ab2c0b29"
      },
      "source": [
        "### dataset load ###\r\n",
        "cifar_train = datasets.CIFAR10(\r\n",
        "    root=args.dataset_dir, \r\n",
        "    train=True, \r\n",
        "    transform=simclr_transform(args.image_size), \r\n",
        "    download=True\r\n",
        ")\r\n",
        "\r\n",
        "if args.debug:\r\n",
        "  cifar_train = torch.utils.data.Subset(cifar_train, range(0, args.debug_subset_size))\r\n",
        "  cifar_train.classes = cifar_train.dataset.classes\r\n",
        "  cifar_train.targets = cifar_train.dataset.targets\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(\r\n",
        "    cifar_train, \r\n",
        "    batch_size=args.batch_size, \r\n",
        "    shuffle=True, \r\n",
        "    num_workers=args.num_workers, \r\n",
        "    drop_last=True, \r\n",
        "    pin_memory=True\r\n",
        ")\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sSKUET0IL1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "ad790240-1e68-4017-8f9b-9768763d1ce6"
      },
      "source": [
        "### dataset load check ###\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def imshow(img):\r\n",
        "  img = img / 2 + 0.5     # unnormalize\r\n",
        "  npimg = img.numpy()\r\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "if args.data_load_check:\r\n",
        "  dataiter = iter(train_loader)\r\n",
        "  (images1, images2), labels = dataiter.next()\r\n",
        "\r\n",
        "  imshow(torchvision.utils.make_grid(images1))\r\n",
        "  imshow(torchvision.utils.make_grid(images2))\r\n",
        "  print(' '.join('%5s' % train_loader.dataset.classes[labels[j]] for j in range(len(labels))))\r\n",
        "  ### ------------------------------------------ ###"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "automobile truck\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2E6ASOUo7PV"
      },
      "source": [
        "### ResNet18 for CIFAR10 define ###\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import os\r\n",
        "# https://raw.githubusercontent.com/huyvnphan/PyTorch_CIFAR10/master/cifar10_models/resnet.py\r\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\r\n",
        "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d']\r\n",
        "\r\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\r\n",
        "  \"\"\"3x3 convolution with padding\"\"\"\r\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\r\n",
        "                    padding=dilation, groups=groups, bias=False, dilation=dilation)\r\n",
        "\r\n",
        "\r\n",
        "def conv1x1(in_planes, out_planes, stride=1):\r\n",
        "  \"\"\"1x1 convolution\"\"\"\r\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\r\n",
        "\r\n",
        "\r\n",
        "class BasicBlock(nn.Module):\r\n",
        "  expansion = 1\r\n",
        "\r\n",
        "  def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\r\n",
        "                base_width=64, dilation=1, norm_layer=None):\r\n",
        "    super(BasicBlock, self).__init__()\r\n",
        "    if norm_layer is None:\r\n",
        "      norm_layer = nn.BatchNorm2d\r\n",
        "    if groups != 1 or base_width != 64:\r\n",
        "      raise ValueError('BasicBlock only supports groups=1 and base_width=64')\r\n",
        "    if dilation > 1:\r\n",
        "      raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\r\n",
        "    # Both self.conv1 and self.downsample layers downsample the input when stride != 1\r\n",
        "    self.conv1 = conv3x3(inplanes, planes, stride)\r\n",
        "    self.bn1 = norm_layer(planes)\r\n",
        "    self.relu = nn.ReLU(inplace=True)\r\n",
        "    self.conv2 = conv3x3(planes, planes)\r\n",
        "    self.bn2 = norm_layer(planes)\r\n",
        "    self.downsample = downsample\r\n",
        "    self.stride = stride\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    identity = x\r\n",
        "\r\n",
        "    out = self.conv1(x)\r\n",
        "    out = self.bn1(out)\r\n",
        "    out = self.relu(out)\r\n",
        "\r\n",
        "    out = self.conv2(out)\r\n",
        "    out = self.bn2(out)\r\n",
        "\r\n",
        "    if self.downsample is not None:\r\n",
        "        identity = self.downsample(x)\r\n",
        "\r\n",
        "    out += identity\r\n",
        "    out = self.relu(out)\r\n",
        "\r\n",
        "    return out\r\n",
        "\r\n",
        "\r\n",
        "class Bottleneck(nn.Module):\r\n",
        "  expansion = 4\r\n",
        "\r\n",
        "  def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\r\n",
        "                base_width=64, dilation=1, norm_layer=None):\r\n",
        "    super(Bottleneck, self).__init__()\r\n",
        "    if norm_layer is None:\r\n",
        "        norm_layer = nn.BatchNorm2d\r\n",
        "    width = int(planes * (base_width / 64.)) * groups\r\n",
        "    # Both self.conv2 and self.downsample layers downsample the input when stride != 1\r\n",
        "    self.conv1 = conv1x1(inplanes, width)\r\n",
        "    self.bn1 = norm_layer(width)\r\n",
        "    self.conv2 = conv3x3(width, width, stride, groups, dilation)\r\n",
        "    self.bn2 = norm_layer(width)\r\n",
        "    self.conv3 = conv1x1(width, planes * self.expansion)\r\n",
        "    self.bn3 = norm_layer(planes * self.expansion)\r\n",
        "    self.relu = nn.ReLU(inplace=True)\r\n",
        "    self.downsample = downsample\r\n",
        "    self.stride = stride\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "      identity = x\r\n",
        "\r\n",
        "      out = self.conv1(x)\r\n",
        "      out = self.bn1(out)\r\n",
        "      out = self.relu(out)\r\n",
        "\r\n",
        "      out = self.conv2(out)\r\n",
        "      out = self.bn2(out)\r\n",
        "      out = self.relu(out)\r\n",
        "\r\n",
        "      out = self.conv3(out)\r\n",
        "      out = self.bn3(out)\r\n",
        "\r\n",
        "      if self.downsample is not None:\r\n",
        "          identity = self.downsample(x)\r\n",
        "\r\n",
        "      out += identity\r\n",
        "      out = self.relu(out)\r\n",
        "\r\n",
        "      return out\r\n",
        "\r\n",
        "\r\n",
        "class ResNet(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, block, layers, num_classes=10, zero_init_residual=False,\r\n",
        "                groups=1, width_per_group=64, replace_stride_with_dilation=None,\r\n",
        "                norm_layer=None):\r\n",
        "    super(ResNet, self).__init__()\r\n",
        "    if norm_layer is None:\r\n",
        "      norm_layer = nn.BatchNorm2d\r\n",
        "    self._norm_layer = norm_layer\r\n",
        "\r\n",
        "    self.inplanes = 64\r\n",
        "    self.dilation = 1\r\n",
        "    if replace_stride_with_dilation is None:\r\n",
        "      # each element in the tuple indicates if we should replace\r\n",
        "      # the 2x2 stride with a dilated convolution instead\r\n",
        "      replace_stride_with_dilation = [False, False, False]\r\n",
        "    if len(replace_stride_with_dilation) != 3:\r\n",
        "      raise ValueError(\"replace_stride_with_dilation should be None \"\r\n",
        "                        \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\r\n",
        "    self.groups = groups\r\n",
        "    self.base_width = width_per_group\r\n",
        "    \r\n",
        "    ## CIFAR10: kernel_size 7 -> 3, stride 2 -> 1, padding 3->1\r\n",
        "    self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\r\n",
        "    ## END\r\n",
        "    \r\n",
        "    self.bn1 = norm_layer(self.inplanes)\r\n",
        "    self.relu = nn.ReLU(inplace=True)\r\n",
        "    # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
        "    self.layer1 = self._make_layer(block, 64, layers[0])\r\n",
        "    self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\r\n",
        "                                    dilate=replace_stride_with_dilation[0])\r\n",
        "    self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\r\n",
        "                                    dilate=replace_stride_with_dilation[1])\r\n",
        "    self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\r\n",
        "                                    dilate=replace_stride_with_dilation[2])\r\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\r\n",
        "    self.fc = nn.Linear(512 * block.expansion, num_classes)\r\n",
        "\r\n",
        "    for m in self.modules():\r\n",
        "      if isinstance(m, nn.Conv2d):\r\n",
        "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n",
        "      elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\r\n",
        "        nn.init.constant_(m.weight, 1)\r\n",
        "        nn.init.constant_(m.bias, 0)\r\n",
        "\r\n",
        "    # Zero-initialize the last BN in each residual branch,\r\n",
        "    # so that the residual branch starts with zeros, and each residual block behaves like an identity.\r\n",
        "    # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\r\n",
        "    if zero_init_residual:\r\n",
        "      for m in self.modules():\r\n",
        "        if isinstance(m, Bottleneck):\r\n",
        "          nn.init.constant_(m.bn3.weight, 0)\r\n",
        "        elif isinstance(m, BasicBlock):\r\n",
        "          nn.init.constant_(m.bn2.weight, 0)\r\n",
        "\r\n",
        "  def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\r\n",
        "    norm_layer = self._norm_layer\r\n",
        "    downsample = None\r\n",
        "    previous_dilation = self.dilation\r\n",
        "    if dilate:\r\n",
        "        self.dilation *= stride\r\n",
        "        stride = 1\r\n",
        "    if stride != 1 or self.inplanes != planes * block.expansion:\r\n",
        "        downsample = nn.Sequential(\r\n",
        "            conv1x1(self.inplanes, planes * block.expansion, stride),\r\n",
        "            norm_layer(planes * block.expansion),\r\n",
        "        )\r\n",
        "\r\n",
        "    layers = []\r\n",
        "    layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\r\n",
        "                        self.base_width, previous_dilation, norm_layer))\r\n",
        "    self.inplanes = planes * block.expansion\r\n",
        "    for _ in range(1, blocks):\r\n",
        "        layers.append(block(self.inplanes, planes, groups=self.groups,\r\n",
        "                            base_width=self.base_width, dilation=self.dilation,\r\n",
        "                            norm_layer=norm_layer))\r\n",
        "\r\n",
        "    return nn.Sequential(*layers)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.conv1(x)\r\n",
        "    x = self.bn1(x)\r\n",
        "    x = self.relu(x)\r\n",
        "    # x = self.maxpool(x)\r\n",
        "\r\n",
        "    x = self.layer1(x)\r\n",
        "    x = self.layer2(x)\r\n",
        "    x = self.layer3(x)\r\n",
        "    x = self.layer4(x)\r\n",
        "\r\n",
        "    x = self.avgpool(x)\r\n",
        "    x = x.reshape(x.size(0), -1)\r\n",
        "    x = self.fc(x)\r\n",
        "\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "def _resnet(arch, block, layers, pretrained, progress, device, **kwargs):\r\n",
        "  model = ResNet(block, layers, **kwargs)\r\n",
        "  if pretrained:\r\n",
        "      script_dir = os.path.dirname(__file__)\r\n",
        "      state_dict = torch.load(script_dir + '/state_dicts/'+arch+'.pt', map_location=device)\r\n",
        "      model.load_state_dict(state_dict)\r\n",
        "  return model\r\n",
        "\r\n",
        "\r\n",
        "def resnet18(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNet-18 model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress, device,\r\n",
        "                  **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnet34(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNet-34 model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress, device,\r\n",
        "                  **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnet50(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNet-50 model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress, device,\r\n",
        "                  **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnet101(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNet-101 model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress, device,\r\n",
        "                  **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnet152(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNet-152 model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress, device,\r\n",
        "                  **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnext50_32x4d(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNeXt-50 32x4d model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  kwargs['groups'] = 32\r\n",
        "  kwargs['width_per_group'] = 4\r\n",
        "  return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3],\r\n",
        "                  pretrained, progress, device, **kwargs)\r\n",
        "\r\n",
        "\r\n",
        "def resnext101_32x8d(pretrained=False, progress=True, device='cpu', **kwargs):\r\n",
        "  \"\"\"Constructs a ResNeXt-101 32x8d model.\r\n",
        "  Args:\r\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "      progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "  \"\"\"\r\n",
        "  kwargs['groups'] = 32\r\n",
        "  kwargs['width_per_group'] = 8\r\n",
        "  return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\r\n",
        "                  pretrained, progress, device, **kwargs)\r\n",
        "\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh_OjbkTKGV-"
      },
      "source": [
        "### resnet call ###\r\n",
        "import copy\r\n",
        "import torch.nn as nn\r\n",
        "from torchvision import models\r\n",
        "\r\n",
        "if args.resnet_version is not None:\r\n",
        "  resnet = eval(f'{args.resnet_version}()')\r\n",
        "  siamresnet = copy.deepcopy(resnet)\r\n",
        "  \r\n",
        "  resnet.output_dim = resnet.fc.in_features\r\n",
        "  resnet.fc = nn.Identity()\r\n",
        "  siamresnet.output_dim = siamresnet.fc.in_features\r\n",
        "  siamresnet.fc = nn.Identity()\r\n",
        "else:\r\n",
        "  raise NotImplementedError(\"Backbone is not implemented!\")\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDkTLBPcy1lv"
      },
      "source": [
        "### siambyol network define ###\r\n",
        "import math\r\n",
        "from torch.nn import functional\r\n",
        "\r\n",
        "hidden_size=4096\r\n",
        "projection_size=256\r\n",
        "\r\n",
        "class MLP(nn.Module):\r\n",
        "  def __init__(self, input_dim):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.net = nn.Sequential(\r\n",
        "        nn.Linear(input_dim, hidden_size), \r\n",
        "        nn.BatchNorm1d(hidden_size, momentum=1-0.9, eps=1e-5), \r\n",
        "        nn.ReLU(inplace=True), \r\n",
        "        nn.Linear(hidden_size, projection_size)\r\n",
        "    )\r\n",
        "  def forward(self, x):\r\n",
        "    return self.net(x)\r\n",
        "\r\n",
        "class BYOL(nn.Module):\r\n",
        "  def __init__(self, backbone):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.backbone=backbone\r\n",
        "    self.projector = MLP(backbone.output_dim)\r\n",
        "    self.online_encoder = nn.Sequential(\r\n",
        "        self.backbone, \r\n",
        "        self.projector,\r\n",
        "    )\r\n",
        "    self.predictor = MLP(projection_size)\r\n",
        "    self.target_encoder = copy.deepcopy(self.online_encoder)\r\n",
        "\r\n",
        "  def set_online(self, model):\r\n",
        "    del self.online_encoder\r\n",
        "    self.online_encoder = copy.deepcopy(model)\r\n",
        "\r\n",
        "  def target_ema(self, k, K, base_tau=0.996):\r\n",
        "    return 1-(1-base_tau)*(math.cos(math.pi*k/K)+1)/2\r\n",
        "\r\n",
        "  def update_moving_average(self, global_step, max_steps):\r\n",
        "    tau = self.target_ema(global_step, max_steps)\r\n",
        "    for online, target in zip(self.online_encoder.parameters(), self.target_encoder.parameters()):\r\n",
        "      target.data = tau*target.data + (1-tau)*online.data\r\n",
        "  \r\n",
        "  def loss_function(self, p, z):\r\n",
        "    p=functional.normalize(p, dim=-1, p=2)\r\n",
        "    z=functional.normalize(z, dim=-1, p=2)\r\n",
        "    return 2 - 2*(p*z).sum(dim=-1)\r\n",
        "\r\n",
        "  def forward(self, x1, x2):\r\n",
        "    z1_online, z2_online = self.online_encoder(x1), self.online_encoder(x2)\r\n",
        "    p1_online, p2_online = self.predictor(z1_online), self.predictor(z2_online)\r\n",
        "    with torch.no_grad():\r\n",
        "      z1_target, z2_target = self.target_encoder(x1), self.target_encoder(x2)\r\n",
        "    \r\n",
        "    loss1, loss2 = self.loss_function(p1_online, z2_target.detach()), self.loss_function(p2_online, z1_target.detach())\r\n",
        "\r\n",
        "    loss = loss1+loss2\r\n",
        "    return loss.mean()\r\n",
        "\r\n",
        "class SiamBYOL(nn.Module):\r\n",
        "  def __init__(self, backbone):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.backbone=backbone\r\n",
        "    self.projector = MLP(backbone.output_dim)\r\n",
        "    self.online_encoder = nn.Sequential(\r\n",
        "        self.backbone, \r\n",
        "        self.projector,\r\n",
        "    )\r\n",
        "    self.predictor = MLP(projection_size)\r\n",
        "    self.target_encoder = None\r\n",
        "  \r\n",
        "  def set_target(self, model):\r\n",
        "    del self.target_encoder\r\n",
        "    self.target_encoder = copy.deepcopy(model)\r\n",
        "  \r\n",
        "  def loss_function(self, p, z):\r\n",
        "    p=functional.normalize(p, dim=-1, p=2)\r\n",
        "    z=functional.normalize(z, dim=-1, p=2)\r\n",
        "    return 2 - 2*(p*z).sum(dim=-1)\r\n",
        "\r\n",
        "  def target_ema(self, k, K, base_tau=0.996):\r\n",
        "    return 1-(1-base_tau)*(math.cos(math.pi*k/K)+1)/2\r\n",
        "\r\n",
        "  def update_moving_average(self, global_step, max_steps):\r\n",
        "    tau = self.target_ema(global_step, max_steps)\r\n",
        "    for online, target in zip(self.online_encoder.parameters(), self.target_encoder.parameters()):\r\n",
        "      target.data = tau*target.data + (1-tau)*online.data\r\n",
        "\r\n",
        "  def forward(self, x1, x2, target):\r\n",
        "    z1_online, z2_online = self.online_encoder(x1), self.online_encoder(x2)\r\n",
        "    p1_online, p2_online = self.predictor(z1_online), self.predictor(z2_online)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      self.set_target(target)\r\n",
        "      z1_target, z2_target = self.target_encoder(x1), self.target_encoder(x2)\r\n",
        "    \r\n",
        "    loss1, loss2 = self.loss_function(p1_online, z2_target.detach()), self.loss_function(p2_online, z1_target.detach())\r\n",
        "\r\n",
        "    loss = loss1+loss2\r\n",
        "    return loss.mean()\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoNT2XuVRa_t"
      },
      "source": [
        "### byol network call ###\r\n",
        "byol = BYOL(resnet)\r\n",
        "\r\n",
        "# model load, check 'pre model path' to load pre model\r\n",
        "if args.current_epochs != 0:\r\n",
        "  pre_model = torch.load('')\r\n",
        "  msg = byol.load_state_dict(pre_model['state_dict'])\r\n",
        "  print(msg)\r\n",
        "\r\n",
        "byol = byol.to(args.device)\r\n",
        "byol = torch.nn.DataParallel(byol)\r\n",
        "\r\n",
        "siambyol = SiamBYOL(siamresnet)\r\n",
        "\r\n",
        "# model load, check 'pre model path' to load pre model\r\n",
        "if args.current_epochs != 0:\r\n",
        "  pre_model = torch.load('')\r\n",
        "  msg = siambyol.load_state_dict(pre_model['state_dict'])\r\n",
        "  print(msg)\r\n",
        "\r\n",
        "siambyol = siambyol.to(args.device)\r\n",
        "siambyol = torch.nn.DataParallel(siambyol)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VonOn4aaUCV2"
      },
      "source": [
        "### optimizer call ###\r\n",
        "from torch.optim import SGD\r\n",
        "\r\n",
        "predictor_prefix = ('module.predictor', 'predictor')\r\n",
        "byol_parameters = [{\r\n",
        "    'name': 'base',\r\n",
        "    'params': [param for name, param in byol.named_parameters() if not name.startswith(predictor_prefix)],\r\n",
        "    'lr': args.learning_rate\r\n",
        "},{\r\n",
        "    'name': 'predictor',\r\n",
        "    'params': [param for name, param in byol.named_parameters() if name.startswith(predictor_prefix)],\r\n",
        "    'lr': args.learning_rate\r\n",
        "}]\r\n",
        "siambyol_parameters = [{\r\n",
        "    'name': 'base',\r\n",
        "    'params': [param for name, param in siambyol.named_parameters() if not name.startswith(predictor_prefix)],\r\n",
        "    'lr': args.learning_rate\r\n",
        "},{\r\n",
        "    'name': 'predictor',\r\n",
        "    'params': [param for name, param in siambyol.named_parameters() if name.startswith(predictor_prefix)],\r\n",
        "    'lr': args.learning_rate\r\n",
        "}]\r\n",
        "\r\n",
        "byol_optimizer = SGD(byol_parameters, lr=args.learning_rate*args.batch_size/256, momentum=0.9)\r\n",
        "siambyol_optimizer = SGD(siambyol_parameters, lr=args.learning_rate*args.batch_size/256, momentum=0.9)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dELIoWzCuZt4"
      },
      "source": [
        "### learning rate scheduler define ###\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "class LR_Scheduler(object):\r\n",
        "  def __init__(self, optimizer, warmup_epochs, warmup_lr, num_epochs, base_lr, final_lr, iter_per_epoch, constant_predictor_lr=False):\r\n",
        "    self.base_lr = base_lr\r\n",
        "    self.constant_predictor_lr = constant_predictor_lr\r\n",
        "    warmup_iter = iter_per_epoch * warmup_epochs\r\n",
        "    warmup_lr_schedule = np.linspace(warmup_lr, base_lr, warmup_iter)\r\n",
        "    decay_iter = iter_per_epoch * (num_epochs - warmup_epochs)\r\n",
        "    cosine_lr_schedule = final_lr+0.5*(base_lr-final_lr)*(1+np.cos(np.pi*np.arange(decay_iter)/decay_iter))\r\n",
        "    \r\n",
        "    self.lr_schedule = np.concatenate((warmup_lr_schedule, cosine_lr_schedule))\r\n",
        "    self.optimizer = optimizer\r\n",
        "    self.iter = 0\r\n",
        "    self.current_lr = 0\r\n",
        "  def step(self):\r\n",
        "    for param_group in self.optimizer.param_groups:\r\n",
        "\r\n",
        "      if self.constant_predictor_lr and param_group['name'] == 'predictor':\r\n",
        "        param_group['lr'] = self.base_lr\r\n",
        "      else:\r\n",
        "        lr = param_group['lr'] = self.lr_schedule[self.iter]\r\n",
        "    \r\n",
        "    self.iter += 1\r\n",
        "    self.current_lr = lr\r\n",
        "    return lr\r\n",
        "  def get_lr(self):\r\n",
        "    return self.current_lr\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHd0qVZ_JYW9"
      },
      "source": [
        "### lr_scheduler define ###\r\n",
        "byol_lr_scheduler = LR_Scheduler(byol_optimizer, args.warmup_epochs, 0, args.num_epochs, args.learning_rate*args.batch_size/256, 0, len(train_loader), constant_predictor_lr=True)\r\n",
        "siambyol_lr_scheduler = LR_Scheduler(siambyol_optimizer, args.warmup_epochs, 0, args.num_epochs, args.learning_rate*args.batch_size/256, 0, len(train_loader), constant_predictor_lr=True)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur2YMpd2Vi-U",
        "outputId": "ada89119-4cd5-47f0-8165-67f659ecb357"
      },
      "source": [
        "### Training ###\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "from collections import defaultdict\r\n",
        "from datetime import datetime\r\n",
        "from tqdm import tqdm\r\n",
        "import os\r\n",
        "\r\n",
        "writer = SummaryWriter()\r\n",
        "\r\n",
        "global_step = 0\r\n",
        "for epoch in tqdm(range(args.current_epochs, args.num_epochs), desc=f'Training'):\r\n",
        "  metrics = defaultdict(list)\r\n",
        "  \r\n",
        "  for step, ((x1, x2), labels) in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{args.num_epochs}')):\r\n",
        "    x1, x2 = x1.cuda(non_blocking=True), x2.cuda(non_blocking=True)\r\n",
        "\r\n",
        "    byol_loss = byol(x1, x2)\r\n",
        "    byol_optimizer.zero_grad()\r\n",
        "    byol_loss.backward()\r\n",
        "    byol_optimizer.step()\r\n",
        "    byol_lr_scheduler.step() # defined scheduler\r\n",
        "    byol.module.update_moving_average(step+1, len(train_loader))\r\n",
        "\r\n",
        "    siambyol_loss = siambyol(x1, x2, byol.module.online_encoder)\r\n",
        "    siambyol_optimizer.zero_grad()\r\n",
        "    siambyol_loss.backward()\r\n",
        "    siambyol_optimizer.step()\r\n",
        "    siambyol_lr_scheduler.step()\r\n",
        "    siambyol.module.update_moving_average(step+1, len(train_loader))\r\n",
        "\r\n",
        "    byol.module.set_online(siambyol.module.target_encoder)\r\n",
        "    \r\n",
        "    writer.add_scalar(\"Loss/train_step\", siambyol_loss, global_step)\r\n",
        "    metrics[\"Loss/train\"].append(siambyol_loss.item())\r\n",
        "    global_step += 1\r\n",
        "  \r\n",
        "  for k, v in metrics.items():\r\n",
        "    writer.add_scalar(k, np.array(v).mean(), epoch+1)\r\n",
        "\r\n",
        "  if (epoch+1)%args.checkpoint_epochs == 0:\r\n",
        "    byol_ckpt_path = os.path.join(tmp_dir, f\"byol_{args.optim}_{epoch+1}.pt\")\r\n",
        "    print(f'Saving model at epoch {epoch+1}')\r\n",
        "    torch.save({\r\n",
        "        'epoch':epoch+1, \r\n",
        "        'state_dict':byol.module.state_dict()\r\n",
        "    }, byol_ckpt_path)\r\n",
        "    siambyol_ckpt_path = os.path.join(tmp_dir, f\"siambyol_{args.optim}_{epoch+1}.pt\")\r\n",
        "    print(f'Saving model at epoch {epoch+1}')\r\n",
        "    torch.save({\r\n",
        "        'epoch':epoch+1, \r\n",
        "        'state_dict':siambyol.module.state_dict()\r\n",
        "    }, siambyol_ckpt_path)\r\n",
        "\r\n",
        "byol_ckpt_path = os.path.join(tmp_dir, f\"byol_{args.optim}_final.pt\")\r\n",
        "print(f'Saving final model at epoch {epoch+1}')\r\n",
        "torch.save({\r\n",
        "    'epoch':epoch+1, \r\n",
        "    'state_dict':byol.module.state_dict()\r\n",
        "}, byol_ckpt_path)\r\n",
        "siambyol_ckpt_path = os.path.join(tmp_dir, f\"siambyol_{args.optim}_final.pt\")\r\n",
        "print(f'Saving final model at epoch {epoch+1}')\r\n",
        "torch.save({\r\n",
        "    'epoch':epoch+1, \r\n",
        "    'state_dict':siambyol.module.state_dict()\r\n",
        "}, siambyol_ckpt_path)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 1/1:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1/1:  25%|██▌       | 1/4 [00:00<00:00,  6.40it/s]\u001b[A\n",
            "Epoch 1/1:  50%|█████     | 2/4 [00:00<00:00,  6.33it/s]\u001b[A\n",
            "Epoch 1/1:  75%|███████▌  | 3/4 [00:00<00:00,  6.30it/s]\u001b[A\n",
            "Epoch 1/1: 100%|██████████| 4/4 [00:00<00:00,  6.17it/s]\n",
            "Training: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving final model at epoch 1\n",
            "Saving final model at epoch 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRogCvo2Wu_2"
      },
      "source": [
        "### Linear Evaluation define ###\r\n",
        "import torch.nn.functional as F \r\n",
        "\r\n",
        "class AverageMeter():\r\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\r\n",
        "    def __init__(self, name, fmt=':f'):\r\n",
        "        self.name = name\r\n",
        "        self.fmt = fmt\r\n",
        "        self.log = []\r\n",
        "        self.val = 0\r\n",
        "        self.avg = 0\r\n",
        "        self.sum = 0\r\n",
        "        self.count = 0\r\n",
        "\r\n",
        "    def reset(self):\r\n",
        "        self.log.append(self.avg)\r\n",
        "        self.val = 0\r\n",
        "        self.avg = 0\r\n",
        "        self.sum = 0\r\n",
        "        self.count = 0\r\n",
        "\r\n",
        "    def update(self, val, n=1):\r\n",
        "        self.val = val\r\n",
        "        self.sum += val * n\r\n",
        "        self.count += n\r\n",
        "        self.avg = self.sum / self.count\r\n",
        "\r\n",
        "    def __str__(self):\r\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\r\n",
        "        return fmtstr.format(**self.__dict__)\r\n",
        "\r\n",
        "def linear_eval(args, eval_from):\r\n",
        "  eval_train_loader = torch.utils.data.DataLoader(\r\n",
        "      torchvision.datasets.CIFAR10(\r\n",
        "          root=args.dataset_dir, \r\n",
        "          train=True, \r\n",
        "          download=False, \r\n",
        "          transform=Transform_single(size=args.image_size, train=True), \r\n",
        "      ), \r\n",
        "      shuffle=True,\r\n",
        "      batch_size=args.batch_size,\r\n",
        "      num_workers=args.num_workers,\r\n",
        "      drop_last=True,\r\n",
        "      pin_memory=True,\r\n",
        "  )\r\n",
        "\r\n",
        "  eval_test_loader = torch.utils.data.DataLoader(\r\n",
        "      torchvision.datasets.CIFAR10(\r\n",
        "          root=args.dataset_dir, \r\n",
        "          train=False, \r\n",
        "          download=False, \r\n",
        "          transform=Transform_single(size=args.image_size, train=False), \r\n",
        "      ), \r\n",
        "      shuffle=False,\r\n",
        "      batch_size=args.batch_size,\r\n",
        "      num_workers=args.num_workers,\r\n",
        "      drop_last=True,\r\n",
        "      pin_memory=True,\r\n",
        "  )\r\n",
        "\r\n",
        "  eval_model = eval(f\"{args.resnet_version}()\")\r\n",
        "  # eval_model = eval(f\"model.{args.resnet_version}()\")\r\n",
        "  eval_model.output_dim = eval_model.fc.in_features\r\n",
        "  eval_model.fc = torch.nn.Identity()\r\n",
        "  eval_classifier = nn.Linear(in_features=eval_model.output_dim, out_features=10, bias=True).to(args.device)\r\n",
        "\r\n",
        "  ###\r\n",
        "  assert eval_from is not None\r\n",
        "  eval_save_dict = torch.load(eval_from, map_location='cuda')\r\n",
        "  eval_msg = eval_model.load_state_dict({k[9:]:v for k, v in eval_save_dict['state_dict'].items() if k.startswith('backbone.')}, strict=True)\r\n",
        "  \r\n",
        "  print(eval_msg)\r\n",
        "  eval_model = eval_model.to(args.device)\r\n",
        "  eval_model = torch.nn.DataParallel(eval_model)\r\n",
        "\r\n",
        "  # if torch.cuda.device_count() > 1: eval_classifier = torch.nn.SyncBatchNorm.convert_sync_batchnorm(eval_classifier)\r\n",
        "  eval_classifier = torch.nn.DataParallel(eval_classifier)\r\n",
        "  # define optimizer 'sgd', eval_classifier, lr=eval_base_lr=30, momentum=eval_optim_momentum-0.9, weight_decay=eval_optim_weight_decay=0\r\n",
        "  predictor_prefix = ('module.predictor', 'predictor')\r\n",
        "  parameters = [{\r\n",
        "      'name': 'base',\r\n",
        "      'params': [param for name, param in eval_classifier.named_parameters() if not name.startswith(predictor_prefix)],\r\n",
        "      'lr': 30\r\n",
        "  },{\r\n",
        "      'name': 'predictor',\r\n",
        "      'params': [param for name, param in eval_classifier.named_parameters() if name.startswith(predictor_prefix)],\r\n",
        "      'lr': 30\r\n",
        "  }]\r\n",
        "  eval_optimizer = torch.optim.SGD(parameters, lr=30, momentum=0.9, weight_decay=0)\r\n",
        "\r\n",
        "  # define lr scheduler\r\n",
        "  eval_lr_scheduler = LR_Scheduler(\r\n",
        "      eval_optimizer,\r\n",
        "      0, 0*args.batch_size/256, \r\n",
        "      30, 30*args.batch_size/256, 0*args.batch_size/256, \r\n",
        "      len(eval_train_loader),\r\n",
        "  )\r\n",
        "\r\n",
        "  eval_loss_meter = AverageMeter(name='Loss')\r\n",
        "  eval_acc_meter = AverageMeter(name='Accuracy')\r\n",
        "\r\n",
        "  # Start training\r\n",
        "  eval_global_progress = tqdm(range(0, args.eval_epochs), desc=f'Evaluating')\r\n",
        "  for epoch in eval_global_progress:\r\n",
        "    eval_loss_meter.reset()\r\n",
        "    eval_model.eval()\r\n",
        "    eval_classifier.train()\r\n",
        "    eval_local_progress = tqdm(eval_train_loader, desc=f'Epoch {epoch}/{args.eval_epochs}', disable=True)\r\n",
        "    \r\n",
        "    for idx, (images, labels) in enumerate(eval_local_progress):\r\n",
        "\r\n",
        "      eval_classifier.zero_grad()\r\n",
        "      with torch.no_grad():\r\n",
        "        eval_feature = eval_model(images.to(args.device))\r\n",
        "\r\n",
        "      eval_preds = eval_classifier(eval_feature)\r\n",
        "\r\n",
        "      eval_loss = F.cross_entropy(eval_preds, labels.to(args.device))\r\n",
        "\r\n",
        "      eval_loss.backward()\r\n",
        "      eval_optimizer.step()\r\n",
        "      eval_loss_meter.update(eval_loss.item())\r\n",
        "      eval_lr = eval_lr_scheduler.step()\r\n",
        "      eval_local_progress.set_postfix({'lr':eval_lr, \"loss\":eval_loss_meter.val, 'loss_avg':eval_loss_meter.avg})\r\n",
        "\r\n",
        "  eval_classifier.eval()\r\n",
        "  eval_correct, eval_total = 0, 0\r\n",
        "  eval_acc_meter.reset()\r\n",
        "  for idx, (images, labels) in enumerate(eval_test_loader):\r\n",
        "    with torch.no_grad():\r\n",
        "      eval_feature = eval_model(images.to(args.device))\r\n",
        "      eval_preds = eval_classifier(eval_feature).argmax(dim=1)\r\n",
        "      eval_correct = (eval_preds == labels.to(args.device)).sum().item()\r\n",
        "      eval_acc_meter.update(eval_correct/eval_preds.shape[0])\r\n",
        "  print(f'Accuracy = {eval_acc_meter.avg*100:.2f}')\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QvV0X8xaDri"
      },
      "source": [
        "### liner evaluation ###\r\n",
        "if args.eval:\r\n",
        "  linear_eval(args, byol_ckpt_path)\r\n",
        "  linear_eval(args, siambyol_ckpt_path)\r\n",
        "### ------------------------------------------ ###"
      ],
      "execution_count": 44,
      "outputs": []
    }
  ]
}